{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"pysrf","text":"<p>Symmetric non-negative matrix factorization with ADMM optimization.</p> <p>pysrf decomposes a symmetric similarity matrix S into a low-rank non-negative embedding W such that S \u2248 WW\u1d40. It handles missing data, supports bounded constraints on reconstructed values, and estimates the factorization rank through cross-validation.</p>"},{"location":"#key-features","title":"Key features","text":"<ul> <li>Missing data: factorize matrices with missing entries (NaN) and recover   a completed matrix.</li> <li>Bounded reconstruction: constrain reconstructed values to a range such   as [0, 1].</li> <li>Rank estimation: select the factorization rank with built-in   cross-validation and sampling-bound estimation.</li> <li>Ensemble clustering: build stable consensus embeddings from multiple   factorization runs.</li> <li>Fast ADMM solver: Cython-accelerated inner loop provides 10-50x speedup   over pure Python.</li> </ul>"},{"location":"#quick-example","title":"Quick example","text":"<pre><code>import numpy as np\nfrom pysrf import SRF\n\n# Your similarity matrix\ns = np.random.rand(100, 100)\ns = (s + s.T) / 2  # make symmetric\n\n# Fit the model\nmodel = SRF(rank=10, max_outer=20, random_state=42)\nembedding = model.fit_transform(s)\n\n# Reconstruct\ns_reconstructed = model.reconstruct()\n</code></pre>"},{"location":"#next-steps","title":"Next steps","text":"<ul> <li>Installation: set up pysrf and compile Cython extensions.</li> <li>Quick start: walk through core workflows step by step.</li> <li>Examples: explore advanced features and full pipelines.</li> <li>API reference: browse the complete API.</li> <li>Development: contribute to pysrf.</li> </ul>"},{"location":"development/","title":"Development","text":""},{"location":"development/#set-up-the-development-environment","title":"Set up the development environment","text":""},{"location":"development/#automated-setup","title":"Automated setup","text":"<p>Run the setup script to install all tools and dependencies:</p> <pre><code>chmod +x setup.sh\n./setup.sh\n</code></pre> <p>The script installs pyenv, Python 3.12.4, Poetry, all dependencies, compiles the Cython extension, and runs the test suite.</p>"},{"location":"development/#manual-setup","title":"Manual setup","text":"<pre><code>curl -sSL https://install.python-poetry.org | python3 -\npoetry install\nmake compile\npoetry run pytest\n</code></pre>"},{"location":"development/#makefile-targets","title":"Makefile targets","text":"<p>The Makefile provides shortcuts for common tasks:</p> <pre><code>make dev           # install dev dependencies and compile Cython\nmake compile       # compile Cython extension\nmake test          # run test suite\nmake test-cov      # run tests with coverage report\nmake lint          # run ruff linter\nmake format        # format code with ruff\nmake clean         # remove build artifacts\nmake docs          # build documentation\nmake docs-serve    # serve documentation locally\n</code></pre>"},{"location":"development/#run-tests","title":"Run tests","text":"<p>Run the full suite:</p> <pre><code>make test\n</code></pre> <p>Run tests with coverage:</p> <pre><code>make test-cov\n</code></pre> <p>Run a specific test file or test function:</p> <pre><code>poetry run pytest tests/test_model.py -v\npoetry run pytest tests/test_model.py::test_srf_fit_complete_data -v\n</code></pre>"},{"location":"development/#code-quality","title":"Code quality","text":""},{"location":"development/#lint-and-format","title":"Lint and format","text":"<p>Check code quality and auto-format:</p> <pre><code>make lint\nmake format\n</code></pre>"},{"location":"development/#type-hints","title":"Type hints","text":"<p>Use Python 3.10+ style type hints in all public functions:</p> <pre><code>from __future__ import annotations\n\ndef my_function(x: np.ndarray, rank: int = 10) -&gt; tuple[np.ndarray, float]:\n    ...\n</code></pre>"},{"location":"development/#cython-extension","title":"Cython extension","text":"<p>The performance-critical inner loop lives in <code>_bsum.pyx</code>. Compile it with:</p> <pre><code>make compile\n\n# or\npoetry run python setup.py build_ext --inplace\n</code></pre> <p>Verify which implementation is active:</p> <pre><code>from pysrf.model import _get_update_w_function\n\nupdate_w = _get_update_w_function()\nprint(f\"Using: {update_w.__module__}\")\n# _bsum    \u2192 Cython (fast)\n# pysrf.model \u2192 pure Python fallback\n</code></pre>"},{"location":"development/#documentation","title":"Documentation","text":""},{"location":"development/#build-and-preview","title":"Build and preview","text":"<pre><code>make docs          # build docs\nmake docs-serve    # serve locally at http://127.0.0.1:8000\n</code></pre>"},{"location":"development/#docstring-format","title":"Docstring format","text":"<p>Use NumPy-style docstrings:</p> <pre><code>def my_function(x: np.ndarray, param: int = 10) -&gt; float:\n    \"\"\"\n    Brief description.\n\n    Longer description explaining the function's purpose and behavior.\n\n    Parameters\n    ----------\n    x : ndarray\n        Description of x.\n    param : int, default=10\n        Description of param.\n\n    Returns\n    -------\n    result : float\n        Description of return value.\n\n    Examples\n    --------\n    &gt;&gt;&gt; result = my_function(np.array([1, 2, 3]))\n    &gt;&gt;&gt; print(result)\n    0.123\n    \"\"\"\n    ...\n</code></pre>"},{"location":"development/#contributing","title":"Contributing","text":"<ol> <li>Fork the repository.</li> <li>Create a feature branch: <code>git checkout -b feature-name</code></li> <li>Make your changes.</li> <li>Run tests: <code>make test</code></li> <li>Format code: <code>make format</code></li> <li>Commit: <code>git commit -m \"Add feature\"</code></li> <li>Push: <code>git push origin feature-name</code></li> <li>Open a pull request.</li> </ol>"},{"location":"development/#guidelines","title":"Guidelines","text":"<ul> <li>Write tests for new features.</li> <li>Maintain type hints.</li> <li>Update documentation.</li> <li>Keep changes focused.</li> <li>Follow existing code style.</li> </ul>"},{"location":"development/#publish-to-pypi","title":"Publish to PyPI","text":"<p>Update the version in <code>pyproject.toml</code>, then build and publish:</p> <pre><code>poetry version patch  # or minor, major\nmake build\npoetry publish\n</code></pre> <p>For a pre-release version:</p> <pre><code>poetry version prerelease\npoetry publish -r testpypi\n</code></pre>"},{"location":"development/#project-structure","title":"Project structure","text":"<pre><code>pysrf/\n\u251c\u2500\u2500 pysrf/              # main package\n\u2502   \u251c\u2500\u2500 __init__.py     # public API\n\u2502   \u251c\u2500\u2500 model.py        # SRF class\n\u2502   \u251c\u2500\u2500 cross_validation.py\n\u2502   \u251c\u2500\u2500 bounds.py       # sampling-bound estimation\n\u2502   \u251c\u2500\u2500 utils.py        # helper functions\n\u2502   \u2514\u2500\u2500 _bsum.pyx       # Cython extension\n\u251c\u2500\u2500 tests/              # test suite\n\u251c\u2500\u2500 docs/               # documentation\n\u251c\u2500\u2500 setup.py            # Cython build (setuptools)\n\u251c\u2500\u2500 Makefile            # development targets\n\u251c\u2500\u2500 pyproject.toml      # project config\n\u2514\u2500\u2500 README.md           # project overview\n</code></pre>"},{"location":"examples/","title":"Examples","text":"<p>These examples demonstrate the full range of pysrf features, from basic factorization to a complete analysis pipeline.</p>"},{"location":"examples/#basic-factorization","title":"Basic factorization","text":"<p>Generate a low-rank similarity matrix and recover its embedding:</p> <pre><code>import numpy as np\nfrom pysrf import SRF\n\n# Ground-truth low-rank matrix\nn, rank = 100, 10\nw_true = np.random.rand(n, rank)\ns = w_true @ w_true.T\n\n# Fit the model\nmodel = SRF(rank=10, random_state=42)\nw = model.fit_transform(s)\ns_hat = model.reconstruct()\n</code></pre> <p>Because the input is exactly rank-10, the reconstruction error is near zero.</p>"},{"location":"examples/#missing-data","title":"Missing data","text":"<p>Mark entries as <code>NaN</code> to simulate incomplete observations. The model fits on the observed entries and fills in the gaps:</p> <pre><code>import numpy as np\nfrom pysrf import SRF\n\nn, rank = 100, 10\nw_true = np.random.rand(n, rank)\ns = w_true @ w_true.T\n\n# Remove 30% of entries\nmask = np.random.rand(n, n) &lt; 0.3\ns[mask] = np.nan\n\nmodel = SRF(rank=10, missing_values=np.nan, random_state=42)\nw = model.fit_transform(s)\ns_completed = model.reconstruct()\n</code></pre>"},{"location":"examples/#cross-validation-for-rank-selection","title":"Cross-validation for rank selection","text":"<p>Sweep over candidate ranks and let <code>cross_val_score</code> pick the best one. Set <code>estimate_sampling_fraction=True</code> to derive the hold-out fraction from the data:</p> <pre><code>from pysrf import cross_val_score, SRF\n\ncv = cross_val_score(\n    s,\n    estimate_sampling_fraction=True,\n    param_grid={\"rank\": [5, 10, 15, 20]},\n    n_repeats=5,\n    n_jobs=-1,\n    random_state=42,\n)\n\nprint(f\"Best rank: {cv.best_params_['rank']}\")\nprint(f\"Best score: {cv.best_score_:.4f}\")\n</code></pre>"},{"location":"examples/#ensemble-and-consensus-clustering","title":"Ensemble and consensus clustering","text":"<p>Combine multiple factorization runs into a stable consensus embedding, then cluster the result. The pipeline uses scikit-learn's <code>Pipeline</code> interface:</p> <pre><code>from sklearn import pipeline\nfrom pysrf.consensus import EnsembleEmbedding, ClusterEmbedding\nfrom pysrf import SRF, cross_val_score\n\n# 1. Select the rank\ncv = cross_val_score(\n    s,\n    estimate_sampling_fraction=True,\n    param_grid={\"rank\": [5, 10, 15, 20]},\n    n_repeats=5,\n    n_jobs=-1,\n)\n\n# 2. Build the ensemble-clustering pipeline\npipe = pipeline.Pipeline(\n    [\n        (\"ensemble\", EnsembleEmbedding(SRF(cv.best_params_), n_runs=50)),\n        (\"cluster\", ClusterEmbedding(min_clusters=2, max_clusters=6, step=1)),\n    ]\n)\n\nconsensus_embedding = pipe.fit_transform(s)\n</code></pre> <p><code>EnsembleEmbedding</code> runs the factorization <code>n_runs</code> times and averages the aligned embeddings. <code>ClusterEmbedding</code> applies consensus clustering to find stable groups.</p>"},{"location":"examples/#value-bounds","title":"Value bounds","text":"<p>Constrain reconstructed values to a fixed range. This is useful when the similarity measure has a known domain, such as [0, 1] for cosine similarity:</p> <pre><code>from pysrf import SRF\n\nmodel = SRF(rank=10, bounds=(0, 1), random_state=42)\nw = model.fit_transform(s)\ns_reconstructed = model.reconstruct()\n\nassert s_reconstructed.min() &gt;= 0\nassert s_reconstructed.max() &lt;= 1\n</code></pre>"},{"location":"examples/#sampling-bound-estimation","title":"Sampling-bound estimation","text":"<p>Estimate the range of hold-out fractions that produce reliable cross-validation scores:</p> <pre><code>from pysrf import estimate_sampling_bounds_fast\n\npmin, pmax, s_denoised = estimate_sampling_bounds_fast(\n    s,\n    n_jobs=-1,\n    random_state=42,\n)\n\nprint(f\"Minimum sampling rate: {pmin:.4f}\")\nprint(f\"Maximum sampling rate: {pmax:.4f}\")\n\n# Use the midpoint for cross-validation\nsampling_rate = 0.5 * (pmin + pmax)\n</code></pre>"},{"location":"examples/#complete-workflow","title":"Complete workflow","text":"<p>This example ties together every step: data generation, noise injection, missing data, sampling-bound estimation, cross-validation, model fitting, and evaluation.</p> <pre><code>import numpy as np\nfrom pysrf import SRF, cross_val_score, estimate_sampling_bounds_fast\n\n# 1. Generate a low-rank matrix with noise and missing entries\nnp.random.seed(42)\nn, true_rank = 100, 8\nw_true = np.random.rand(n, true_rank)\ns = w_true @ w_true.T\ns += 0.1 * np.random.randn(n, n)\ns = (s + s.T) / 2\nmask = np.random.rand(n, n) &lt; 0.2\ns[mask] = np.nan\n\n# 2. Estimate sampling bounds\npmin, pmax, _ = estimate_sampling_bounds_fast(s, n_jobs=-1)\nprint(f\"Sampling bounds: [{pmin:.3f}, {pmax:.3f}]\")\n\n# 3. Cross-validate to find the best rank\nresult = cross_val_score(\n    s,\n    param_grid={\"rank\": range(5, 21)},\n    estimate_sampling_fraction=True,\n    n_repeats=3,\n    n_jobs=-1,\n    random_state=42,\n)\nbest_rank = result.best_params_[\"rank\"]\nprint(f\"Best rank: {best_rank} (true rank: {true_rank})\")\n\n# 4. Fit the final model\nmodel = SRF(rank=best_rank, max_outer=20, random_state=42)\nw = model.fit_transform(s)\ns_completed = model.reconstruct()\n\n# 5. Evaluate\nscore = model.score(s)\nprint(f\"Reconstruction error: {score:.4f}\")\n</code></pre>"},{"location":"installation/","title":"Installation","text":"<p>Cython compilation</p> <p>Compiling the Cython extension gives a 10-50x speedup. Without it, pysrf falls back to a pure Python implementation. Make sure you have a C compiler installed before proceeding.</p>"},{"location":"installation/#automated-setup-recommended","title":"Automated setup (recommended)","text":"<p>Clone the repository and run the setup script:</p> <pre><code>git clone https://github.com/fmahner/pysrf.git\ncd pysrf\n./setup.sh\n</code></pre> <p>The script performs the following steps:</p> <ol> <li>Installs <code>pyenv</code> if it is not already present.</li> <li>Installs <code>poetry</code> if it is not already present.</li> <li>Installs Python 3.12.4 through <code>pyenv</code>.</li> <li>Sets the local Python version.</li> <li>Installs all dependencies through <code>poetry</code>.</li> <li>Compiles the Cython extension.</li> <li>Runs the test suite.</li> </ol> <p>After the script finishes, activate the environment:</p> <pre><code>poetry shell\n</code></pre>"},{"location":"installation/#manual-installation","title":"Manual installation","text":""},{"location":"installation/#install-prerequisites","title":"Install prerequisites","text":"<p>Install pyenv and poetry if you do not have them:</p> <pre><code>curl https://pyenv.run | bash\ncurl -sSL https://install.python-poetry.org | python3 -\n</code></pre>"},{"location":"installation/#set-up-python","title":"Set up python","text":"<p>Install Python 3.12.4 (or any version &gt;=3.10) and pin it for this project:</p> <pre><code>pyenv install 3.12.4\npyenv local 3.12.4\n</code></pre>"},{"location":"installation/#install-dependencies","title":"Install dependencies","text":"<pre><code>poetry install\n</code></pre>"},{"location":"installation/#compile-the-cython-extension","title":"Compile the Cython extension","text":"<p>Use the Makefile target or run the build command directly:</p> <pre><code>make compile\n\n# or\npoetry run python setup.py build_ext --inplace\n</code></pre> <p>The Makefile provides additional targets:</p> <ul> <li><code>make dev</code>: install dev dependencies and compile Cython.</li> <li><code>make test</code>: run the test suite.</li> <li><code>make format</code>: format code with ruff.</li> <li><code>make clean</code>: remove build artifacts.</li> <li><code>make docs</code>: build documentation.</li> </ul>"},{"location":"installation/#alternative-methods","title":"Alternative methods","text":""},{"location":"installation/#from-pypi-planned","title":"From PyPI (planned)","text":"<pre><code>pip install pysrf\n\n# development version\npip install --pre pysrf\n</code></pre>"},{"location":"installation/#as-a-git-subtree","title":"As a git subtree","text":"<p>Add pysrf as a subtree inside another project:</p> <pre><code>git subtree add --prefix=pysrf https://github.com/fmahner/pysrf.git master --squash\n</code></pre> <p>Update the subtree:</p> <pre><code>git subtree pull --prefix=pysrf https://github.com/fmahner/pysrf.git master --squash\n</code></pre> <p>Then install and compile:</p> <pre><code>cd pysrf &amp;&amp; poetry install &amp;&amp; make compile\n</code></pre>"},{"location":"installation/#verify-the-installation","title":"Verify the installation","text":"<pre><code>import pysrf\nprint(pysrf.__version__)\n\n# Check whether the Cython extension is active\nfrom pysrf.model import _get_update_w_function\nupdate_w = _get_update_w_function()\nprint(f\"Using: {update_w.__module__}\")  # _bsum if compiled\n</code></pre>"},{"location":"quickstart/","title":"Quick start","text":"<p>This guide walks you through the core pysrf workflows: factorizing a similarity matrix, handling missing data, and selecting the factorization rank with cross-validation.</p>"},{"location":"quickstart/#factorize-a-symmetric-matrix","title":"Factorize a symmetric matrix","text":"<p>Create an <code>SRF</code> model, choose a rank, and call <code>fit_transform</code> to obtain the non-negative embedding W. The reconstruction WW\u1d40 approximates the original matrix.</p> <pre><code>import numpy as np\nfrom pysrf import SRF\n\n# Generate or load your similarity matrix\ns = np.random.rand(100, 100)\ns = (s + s.T) / 2  # ensure symmetry\n\n# Fit the model\nmodel = SRF(rank=10, max_outer=20, random_state=42)\nw = model.fit_transform(s)\n\n# Reconstruct the matrix\ns_reconstructed = model.reconstruct()\n# or equivalently: s_reconstructed = w @ w.T\n\n# Evaluate fit\nscore = model.score(s)\nprint(f\"Reconstruction error: {score:.4f}\")\n</code></pre> <p>The <code>score</code> method returns the Frobenius-norm reconstruction error, which you can use to compare models at different ranks.</p>"},{"location":"quickstart/#handle-missing-data","title":"Handle missing data","text":"<p>Pass a matrix that contains <code>NaN</code> entries. Set <code>missing_values=np.nan</code> so the model ignores those positions during fitting and fills them in during reconstruction.</p> <pre><code>import numpy as np\nfrom pysrf import SRF\n\n# Matrix with 30% missing values\ns = np.random.rand(100, 100)\ns = (s + s.T) / 2\ns[np.random.rand(100, 100) &lt; 0.3] = np.nan\n\n# Fit \u2014 missing entries are excluded automatically\nmodel = SRF(rank=10, missing_values=np.nan, random_state=42)\nw = model.fit_transform(s)\ns_completed = model.reconstruct()\n</code></pre> <p>The completed matrix <code>s_completed</code> contains predicted values in place of the original <code>NaN</code> entries.</p>"},{"location":"quickstart/#select-the-rank-with-cross-validation","title":"Select the rank with cross-validation","text":"<p>Use <code>cross_val_score</code> to evaluate a grid of candidate ranks. The function holds out a fraction of observed entries, fits the model on the rest, and scores reconstruction quality on the held-out set.</p> <pre><code>from pysrf import cross_val_score\n\ns = np.random.rand(100, 100)\ns = (s + s.T) / 2\n\ncv = cross_val_score(s, param_grid={\"rank\": [5, 10, 15, 20]})\n\nprint(f\"Best parameters: {cv.best_params_}\")\nprint(f\"Best score: {cv.best_score_:.4f}\")\n</code></pre> <p>For a deeper dive into cross-validation options, sampling-bound estimation, and ensemble clustering, see the Examples page.</p>"},{"location":"api/bounds/","title":"Sampling Bounds API","text":""},{"location":"api/bounds/#main-functions","title":"Main Functions","text":""},{"location":"api/bounds/#pysrf.estimate_sampling_bounds_fast","title":"estimate_sampling_bounds_fast","text":"<pre><code>estimate_sampling_bounds_fast(\n    S: np.ndarray,\n    gamma: float = 1.05,\n    eta: float = 0.05,\n    rho: float = 0.95,\n    method: str = \"dyson\",\n    omega: float = 0.8,\n    eta_pmax: float = 0.001,\n    jump_frac: float = 0.1,\n    tol: float = 0.0001,\n    gap: float = 0.05,\n    random_state: int = 31213,\n    n_jobs: int = -1,\n) -&gt; tuple[float, float, np.ndarray]\n</code></pre> Source code in <code>pysrf/bounds.py</code> <pre><code>def estimate_sampling_bounds_fast(\n    S: np.ndarray,\n    gamma: float = 1.05,\n    eta: float = 0.05,\n    rho: float = 0.95,\n    method: str = \"dyson\",\n    omega: float = 0.8,\n    eta_pmax: float = 1e-3,\n    jump_frac: float = 0.1,\n    tol: float = 1e-4,\n    gap: float = 0.05,\n    random_state: int = 31213,\n    n_jobs: int = -1,\n) -&gt; tuple[float, float, np.ndarray]:\n    pmin, _, _, _, _ = pmin_bound(\n        S,\n        gamma=gamma,\n        eta=eta,\n        rho=rho,\n        random_state=random_state,\n    )\n\n    eff_dim = np.ceil((np.linalg.norm(S, \"fro\") / np.linalg.norm(S, 2)) ** 2).astype(\n        int\n    )\n\n    pmax = p_upper_only_k(\n        S,\n        k=eff_dim,\n        method=method,\n        tol=tol,\n        omega=omega,\n        eta=eta_pmax,\n        jump_frac=jump_frac,\n        seed=random_state,\n    )\n\n    S_noise = S\n\n    if pmin &gt; pmax - gap:\n        epsilon = np.linalg.norm(S, 2) / np.sqrt(S.shape[0])\n        t_range = np.linspace(0.0, epsilon, 10)\n\n        A = np.random.rand(S.shape[0], S.shape[1])\n        AtA = A + A.T\n\n        def _eval_t(t):\n            S_t = S + t * AtA\n            pmin_t, _, _, _, _ = pmin_bound(\n                S_t,\n                gamma=gamma,\n                eta=eta,\n                rho=rho,\n                random_state=random_state,\n            )\n            eff_dim_t = np.ceil(\n                (np.linalg.norm(S_t, \"fro\") / np.linalg.norm(S_t, 2)) ** 2\n            ).astype(int)\n            pmax_t = p_upper_only_k(\n                S_t,\n                k=eff_dim_t,\n                method=method,\n                tol=tol,\n                omega=omega,\n                eta=eta_pmax,\n                jump_frac=jump_frac,\n                seed=random_state,\n            )\n            return float(pmin_t), float(pmax_t)\n\n        results = Parallel(n_jobs=n_jobs)(delayed(_eval_t)(float(t)) for t in t_range)\n\n        idx = None\n        for i, (pm, px) in enumerate(results):\n            if pm &lt; px - gap:\n                idx = i\n                break\n\n        if idx is not None:\n            t_threshold = float(t_range[idx])\n            pmin, pmax = results[idx]\n        else:\n            t_threshold = 0.0\n            pmin, pmax = results[-1]\n\n        S_noise = S + t_threshold * AtA\n\n    return pmin, pmax, S_noise\n</code></pre>"},{"location":"api/bounds/#pysrf.estimate_sampling_bounds","title":"estimate_sampling_bounds","text":"<pre><code>estimate_sampling_bounds(\n    S: np.ndarray,\n    gamma: float = 1.05,\n    eta: float = 0.05,\n    rho: float = 0.95,\n    method: str = \"dyson\",\n    omega: float = 0.8,\n    eta_pmax: float = 0.001,\n    jump_frac: float = 0.1,\n    tol: float = 0.0001,\n    gap: float = 0.05,\n    random_state: int = 31213,\n) -&gt; tuple[float, float, np.ndarray]\n</code></pre> Source code in <code>pysrf/bounds.py</code> <pre><code>def estimate_sampling_bounds(\n    S: np.ndarray,\n    gamma: float = 1.05,\n    eta: float = 0.05,\n    rho: float = 0.95,\n    method: str = \"dyson\",\n    omega: float = 0.8,\n    eta_pmax: float = 1e-3,\n    jump_frac: float = 0.1,\n    tol: float = 1e-4,\n    gap: float = 0.05,\n    random_state: int = 31213,\n) -&gt; tuple[float, float, np.ndarray]:\n    pmin, _, _, _, _ = pmin_bound(\n        S,\n        gamma=gamma,\n        eta=eta,\n        rho=rho,\n        random_state=random_state,\n    )\n\n    eff_dim = np.ceil((np.linalg.norm(S, \"fro\") / np.linalg.norm(S, 2)) ** 2).astype(\n        int\n    )\n\n    pmax = p_upper_only_k(\n        S,\n        k=eff_dim,\n        method=method,\n        tol=tol,\n        omega=omega,\n        eta=eta_pmax,\n        jump_frac=jump_frac,\n        seed=random_state,\n    )\n\n    S_noise = S\n\n    if pmin &gt; pmax - gap:\n        logger.info(\"Noise regime triggered, pmin=%.4f, pmax=%.4f\", pmin, pmax)\n\n        epsilon = np.linalg.norm(S, 2) / np.sqrt(S.shape[0])\n\n        t_range = np.linspace(0.0, epsilon, 10)\n        eff_dim_list = []\n        pmin_list = []\n        pmax_list = []\n\n        A = np.random.rand(S.shape[0], S.shape[1])\n\n        t_threshold = 0\n\n        t_iter = iter(t_range)\n        t = next(t_iter)\n\n        while True:\n            S_noise = S + t * (A + A.T)\n\n            pmin, _, _, _, _ = pmin_bound(\n                S_noise,\n                gamma=gamma,\n                eta=eta,\n                rho=rho,\n                random_state=random_state,\n            )\n\n            eff_dim = np.ceil(\n                (np.linalg.norm(S_noise, \"fro\") / np.linalg.norm(S_noise, 2)) ** 2\n            ).astype(int)\n            pmax = p_upper_only_k(\n                S_noise,\n                k=eff_dim,\n                method=method,\n                tol=tol,\n                omega=omega,\n                eta=eta_pmax,\n                jump_frac=jump_frac,\n                seed=random_state,\n            )\n            logger.info(\n                \"t=%.4f, pmin=%.4f, eff_dim=%d, pmax=%.4f\", t, pmin, eff_dim, pmax\n            )\n\n            eff_dim_list.append(eff_dim)\n            pmin_list.append(pmin)\n            pmax_list.append(pmax)\n\n            if pmin &lt; pmax - gap:\n                t_threshold = t\n                break\n\n            try:\n                t = next(t_iter)\n            except StopIteration:\n                break\n\n        S_noise = S + t_threshold * (A + A.T)\n\n    return pmin, pmax, S_noise\n</code></pre>"},{"location":"api/bounds/#lower-bound-estimation","title":"Lower Bound Estimation","text":""},{"location":"api/bounds/#pysrf.pmin_bound","title":"pmin_bound","text":"<pre><code>pmin_bound(\n    S: np.ndarray,\n    gamma: float = 1.05,\n    eta: float = 0.05,\n    rho: float = 0.95,\n    n_realizations: int = 500,\n    random_state: int | None = None,\n    monte_carlo: bool = False,\n) -&gt; tuple[float, float, float, float, np.ndarray]\n</code></pre> Source code in <code>pysrf/bounds.py</code> <pre><code>def pmin_bound(\n    S: np.ndarray,\n    gamma: float = 1.05,\n    eta: float = 0.05,\n    rho: float = 0.95,\n    n_realizations: int = 500,\n    random_state: int | None = None,\n    monte_carlo: bool = False,\n) -&gt; tuple[float, float, float, float, np.ndarray]:\n    np.random.seed(random_state)\n    n = S.shape[0]\n    _is_symmetric = np.allclose(S, S.T)\n\n    L_max = np.max((S**2).sum(axis=1) - np.diag(S) ** 2)\n\n    _row_sq = (S**2).sum(axis=1) - np.diag(S) ** 2\n    empirical_L_max = np.quantile(_row_sq, rho)\n\n    S_norm = np.linalg.norm(S, 2)\n\n    L_infty = 2 * np.max(np.abs(S))\n    empirical_L_infty = 2 * np.quantile(np.abs(S), rho)\n\n    effective_dimension = (np.linalg.norm(S, \"fro\") / S_norm) ** 2\n    logger.info(\"effective dimension: %s\", effective_dimension)\n\n    MC_expected_MS_norms = np.zeros(n_realizations)\n    if monte_carlo:\n        for i in range(n_realizations):\n            _p = np.random.rand()\n            _mask = np.random.binomial(1, _p, size=S.shape)\n            if _is_symmetric:\n                _mask = np.triu(_mask, 1)\n                _mask += _mask.T\n            MC_expected_MS_norms[i] = np.linalg.norm(_mask * S, 2)\n\n    N_bernstein = (gamma * L_infty * S_norm) / (3 * L_max) + 1\n    N_empirical = (gamma * empirical_L_infty * S_norm) / (3 * empirical_L_max) + 1\n    N_empirical_alternative = (gamma * L_infty * S_norm) / (3 * empirical_L_max) + 1\n    N_theory_upperbound = (gamma * S_norm) / 3 + 1\n\n    D_bernstein = ((gamma * S_norm) ** 2 / (2 * L_max) + 1) / np.log(2 * n / eta)\n    D_empirical = ((gamma * S_norm) ** 2 / (2 * empirical_L_max) + 1) / np.log(\n        2 * effective_dimension / eta\n    )\n    D_theory_lowerbound = ((gamma**2 * S_norm) / (2 * empirical_L_max) + 1) / np.log(\n        2 * n / eta\n    )\n\n    logger.info(\n        \"N_bernstein=%.4f, D_bernstein=%.4f, N_empirical=%.4f, D_empirical=%.4f, \"\n        \"N_empirical_alt=%.4f, N_theory_ub=%.4f, D_theory_lb=%.4f\",\n        N_bernstein,\n        D_bernstein,\n        N_empirical,\n        D_empirical,\n        N_empirical_alternative,\n        N_theory_upperbound,\n        D_theory_lowerbound,\n    )\n\n    p_min = N_bernstein / D_bernstein\n    p_min_empirical = N_empirical / D_empirical\n    p_min_empirical_alternative = N_empirical_alternative / D_empirical\n    p_min_lowerbound = N_theory_upperbound / D_theory_lowerbound\n\n    logger.info(\n        \"p_min=%.4f, empirical_p_min=%.4f, empirical_p_min_alt=%.4f, theory_p_min=%.4f\",\n        p_min,\n        p_min_empirical,\n        p_min_empirical_alternative,\n        p_min_lowerbound,\n    )\n\n    return (\n        p_min_empirical,\n        p_min,\n        p_min_lowerbound,\n        p_min_empirical_alternative,\n        MC_expected_MS_norms,\n    )\n</code></pre>"},{"location":"api/bounds/#upper-bound-estimation","title":"Upper Bound Estimation","text":""},{"location":"api/bounds/#pysrf.p_upper_only_k","title":"p_upper_only_k","text":"<pre><code>p_upper_only_k(\n    S: np.ndarray,\n    k: int = 1,\n    method: str = \"dyson\",\n    mc_trials: int = 600,\n    mc_quantile: float = 0.9,\n    tol: float = 0.0001,\n    seed: int | None = None,\n    omega: float = 0.8,\n    eta: float = 0.001,\n    jump_frac: float = 0.1,\n) -&gt; float\n</code></pre> Source code in <code>pysrf/bounds.py</code> <pre><code>def p_upper_only_k(\n    S: np.ndarray,\n    k: int = 1,\n    method: str = \"dyson\",\n    mc_trials: int = 600,\n    mc_quantile: float = 0.9,\n    tol: float = 1e-4,\n    seed: int | None = None,\n    omega: float = 0.8,\n    eta: float = 1e-3,\n    jump_frac: float = 0.1,\n) -&gt; float:\n    lam = np.sort(eigvalsh(S))[::-1]\n    n = len(lam)\n    if not (1 &lt;= k &lt;= n):\n        raise ValueError(\"k must be between 1 and n\")\n    lam_k = lam[k - 1]\n    lam_k1 = lam[k] if k &lt; n else None\n\n    if lam_k &lt;= 0:\n        logger.info(\"lambda_k &lt;= 0 -&gt; no positive spike to separate.\")\n        return 0.0\n    if (lam_k1 is None) or (lam_k1 &lt;= 0):\n        logger.info(\n            \"lambda_{k+1} &lt;= 0 -&gt; only first k can be out for all large p; return 1.0.\"\n        )\n        return 1.0\n\n    edge = (\n        (\n            lambda p: lambda_bulk_dyson_raw(\n                S, p, omega=omega, eta=eta, jump_frac=jump_frac\n            )\n        )\n        if method == \"dyson\"\n        else (\n            lambda p: monte_carlo_bulk_edge_raw(\n                S, p, n_trials=mc_trials, quantile=mc_quantile, seed=seed\n            )\n        )\n    )\n\n    def count_out(p):\n        e = edge(p)\n        return int(np.sum(p * lam &gt; e)), e\n\n    c_hi, e_hi = count_out(0.99)\n    logger.info(\n        \"[sanity] p=0.99: bulk=%.4g, count_out=%d, lambda1=%.4g, lambda2=%.4g\",\n        e_hi,\n        c_hi,\n        lam[0],\n        lam[1] if n &gt; 1 else np.nan,\n    )\n\n    if c_hi &lt; k:\n        logger.info(\"Even at p~1, only %d spikes out (&lt; k). Returning 1.0.\", c_hi)\n        return 1.0\n\n    grid = np.linspace(0.02, 0.99, 80)\n    feas = [p for p in grid if count_out(p)[0] == k]\n    if not feas:\n\n        def g(p):\n            return p * lam_k1 - edge(p)\n\n        a, b = 1e-3, 0.99\n        ga, gb = g(a), g(b)\n\n        if ga &gt;= 0 and gb &gt;= 0:\n            logger.info(\n                \"(k+1) spike is out for all p; returning smallest p where count==k (none found) -&gt; 0.\"\n            )\n            return 0.0\n\n        if ga &lt; 0 and gb &lt;= 0:\n            logger.info(\"(k+1) never emerges up to 0.99; returning 1.0.\")\n            return 1.0\n\n        lo, hi = a, b\n        for _ in range(60):\n            mid = 0.5 * (lo + hi)\n            if g(mid) &gt;= 0:\n                hi = mid\n            else:\n                lo = mid\n            if (hi - lo) &lt; tol:\n                break\n\n        p_star = max(0.0, min(1.0, lo - 2 * tol))\n\n        return p_star\n\n    p_lo = max(feas)\n\n    def cond_ge_kplus1(p):\n        return count_out(p)[0] &gt;= (k + 1)\n\n    p_hi = min(0.99, p_lo + 0.05)\n    while (p_hi &lt; 0.99) and (not cond_ge_kplus1(p_hi)):\n        p_hi = min(0.99, p_hi + 0.05)\n    if not cond_ge_kplus1(p_hi):\n        return 1.0\n    lo, hi = p_lo, p_hi\n    for _ in range(60):\n        mid = 0.5 * (lo + hi)\n        if cond_ge_kplus1(mid):\n            hi = mid\n        else:\n            lo = mid\n        if (hi - lo) &lt; tol:\n            break\n    p_star = max(0.0, min(1.0, lo))\n    c_star, e_star = count_out(p_star)\n    logger.info(\"p*=%.4f, bulk=%.6g, count_out(p*)=%d\", p_star, e_star, c_star)\n    return p_star\n</code></pre>"},{"location":"api/cross_validation/","title":"Cross-Validation API","text":""},{"location":"api/cross_validation/#pysrf.cross_val_score","title":"cross_val_score","text":"<pre><code>cross_val_score(\n    similarity_matrix: np.ndarray,\n    estimator: BaseEstimator | None = None,\n    param_grid: dict[str, list] | None = None,\n    n_repeats: int = 5,\n    sampling_fraction: float = 0.8,\n    estimate_sampling_fraction: bool | dict = False,\n    sampling_selection: str = \"mean\",\n    random_state: int = 0,\n    verbose: int = 1,\n    n_jobs: int = -1,\n    missing_values: float | None = np.nan,\n    fit_final_estimator: bool = False,\n) -&gt; GridSearchCV\n</code></pre> <p>Cross-validate any estimator for matrix completion.</p> <p>Generic cross-validation function that works with SRF or any sklearn-compatible estimator with a .reconstruct() method.</p> <p>Parameters:</p> Name Type Description Default <code>similarity_matrix</code> <code>ndarray</code> <p>Symmetric similarity matrix to cross-validate</p> required <code>estimator</code> <code>BaseEstimator or None</code> <p>Estimator to cross-validate. If None, uses SRF(random_state=random_state). Can be a single estimator or a Pipeline. Must have a .reconstruct() method.</p> <code>None</code> <code>param_grid</code> <code>dict or None</code> <p>Dictionary with parameter names (str) as keys and lists of values to try as values. If None, uses default {'rank': [5, 10, 15, 20]} for SRF.</p> <code>None</code> <code>n_repeats</code> <code>int</code> <p>Number of times to repeat the cross-validation</p> <code>5</code> <code>sampling_fraction</code> <code>float</code> <p>Fraction of eligible entries to use for training in each split; must be in (0, 1). The remaining (1 - sampling_fraction) becomes validation. Note: Constant diagonal entries are excluded from both train and validation. Ignored when estimate_sampling_fraction is True or a dict; if both are provided, estimate_sampling_fraction takes precedence.</p> <code>0.8</code> <code>estimate_sampling_fraction</code> <code>bool or dict</code> <p>If True, automatically estimate optimal sampling fraction using sampling bound estimation from Random Matrix Theory. If dict, passed as kwargs to estimate_sampling_bounds_fast(). When enabled, overrides sampling_fraction.</p> <code>False</code> <code>sampling_selection</code> <code>str</code> <p>Selection method for the estimated sampling fraction; one of {\"mean\", \"min\", \"max\"}.</p> <code>\"mean\"</code> <code>random_state</code> <code>int</code> <p>Random seed for reproducibility</p> <code>0</code> <code>verbose</code> <code>int</code> <p>Verbosity level</p> <code>1</code> <code>n_jobs</code> <code>int</code> <p>Number of jobs to run in parallel (-1 uses all processors)</p> <code>-1</code> <code>missing_values</code> <code>float or None</code> <p>Value to consider as missing in original data</p> <code>np.nan</code> <code>fit_final_estimator</code> <code>bool</code> <p>Whether to fit the final estimator on the best parameters</p> <code>False</code> <p>Returns:</p> Name Type Description <code>grid</code> <code>GridSearchCV</code> <p>Fitted GridSearchCV object with best parameters and scores</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from pysrf.cross_validation import cross_val_score\n&gt;&gt;&gt; result = cross_val_score(similarity_matrix, param_grid={'rank': [5, 10, 15]})\n</code></pre> Source code in <code>pysrf/cross_validation.py</code> <pre><code>def cross_val_score(\n    similarity_matrix: np.ndarray,\n    estimator: BaseEstimator | None = None,\n    param_grid: dict[str, list] | None = None,\n    n_repeats: int = 5,\n    sampling_fraction: float = 0.8,\n    estimate_sampling_fraction: bool | dict = False,\n    sampling_selection: str = \"mean\",\n    random_state: int = 0,\n    verbose: int = 1,\n    n_jobs: int = -1,\n    missing_values: float | None = np.nan,\n    fit_final_estimator: bool = False,\n) -&gt; GridSearchCV:\n    \"\"\"\n    Cross-validate any estimator for matrix completion.\n\n    Generic cross-validation function that works with SRF or any sklearn-compatible\n    estimator with a .reconstruct() method.\n\n    Parameters\n    ----------\n    similarity_matrix : ndarray\n        Symmetric similarity matrix to cross-validate\n    estimator : BaseEstimator or None, default=None\n        Estimator to cross-validate. If None, uses SRF(random_state=random_state).\n        Can be a single estimator or a Pipeline. Must have a .reconstruct() method.\n    param_grid : dict or None, default=None\n        Dictionary with parameter names (str) as keys and lists of values to try\n        as values. If None, uses default {'rank': [5, 10, 15, 20]} for SRF.\n    n_repeats : int, default=5\n        Number of times to repeat the cross-validation\n    sampling_fraction : float, default=0.8\n        Fraction of eligible entries to use for training in each split; must be in (0, 1).\n        The remaining (1 - sampling_fraction) becomes validation.\n        Note: Constant diagonal entries are excluded from both train and validation.\n        Ignored when estimate_sampling_fraction is True or a dict; if both are provided,\n        estimate_sampling_fraction takes precedence.\n    estimate_sampling_fraction : bool or dict, default=False\n        If True, automatically estimate optimal sampling fraction using sampling\n        bound estimation from Random Matrix Theory. If dict, passed as kwargs to\n        estimate_sampling_bounds_fast(). When enabled, overrides sampling_fraction.\n    sampling_selection : str, default=\"mean\"\n        Selection method for the estimated sampling fraction; one of {\"mean\", \"min\", \"max\"}.\n    random_state : int, default=0\n        Random seed for reproducibility\n    verbose : int, default=1\n        Verbosity level\n    n_jobs : int, default=-1\n        Number of jobs to run in parallel (-1 uses all processors)\n    missing_values : float or None, default=np.nan\n        Value to consider as missing in original data\n    fit_final_estimator : bool, default=False\n        Whether to fit the final estimator on the best parameters\n\n    Returns\n    -------\n    grid : GridSearchCV\n        Fitted GridSearchCV object with best parameters and scores\n\n    Examples\n    --------\n    &gt;&gt;&gt; from pysrf.cross_validation import cross_val_score\n    &gt;&gt;&gt; result = cross_val_score(similarity_matrix, param_grid={'rank': [5, 10, 15]})\n    \"\"\"\n    if estimator is None:\n        estimator = SRF(random_state=random_state)\n\n    if param_grid is None:\n        param_grid = {\"rank\": [5, 10, 15, 20]}\n\n    valid_selections = {\"mean\", \"min\", \"max\"}\n    if sampling_selection not in valid_selections:\n        raise ValueError(\n            f\"sampling_selection must be one of {sorted(valid_selections)}\"\n        )\n\n    if estimate_sampling_fraction:\n        from .bounds import estimate_sampling_bounds_fast\n\n        kwargs = (\n            estimate_sampling_fraction\n            if isinstance(estimate_sampling_fraction, dict)\n            else {}\n        )\n        if \"random_state\" not in kwargs:\n            kwargs[\"random_state\"] = random_state\n        if \"n_jobs\" not in kwargs:\n            kwargs[\"n_jobs\"] = n_jobs\n        kwargs.pop(\"verbose\", None)\n\n        pmin, pmax, s_noise = estimate_sampling_bounds_fast(similarity_matrix, **kwargs)\n        sampling_fraction = {\n            \"mean\": np.mean([pmin, pmax]),\n            \"min\": pmin,\n            \"max\": pmax,\n        }[sampling_selection]\n\n    else:\n        _validate_sampling_fraction(sampling_fraction)\n\n    cv = EntryMaskSplit(\n        n_repeats=n_repeats,\n        sampling_fraction=sampling_fraction,\n        random_state=random_state,\n        missing_values=missing_values,\n    )\n    grid = GridSearchCV(\n        estimator=estimator,\n        param_grid=param_grid,\n        cv=cv,\n        n_jobs=n_jobs,\n        verbose=verbose,\n        fit_final_estimator=fit_final_estimator,\n    )\n    grid.fit(similarity_matrix)\n\n    return grid\n</code></pre>"},{"location":"api/cross_validation/#grid-search","title":"Grid Search","text":""},{"location":"api/cross_validation/#pysrf.GridSearchCV","title":"GridSearchCV","text":"<pre><code>GridSearchCV(\n    estimator: BaseEstimator,\n    param_grid: dict[str, list],\n    cv: EntryMaskSplit,\n    n_jobs: int = -1,\n    verbose: int = 0,\n    fit_final_estimator: bool = False,\n)\n</code></pre> <p>Grid search cross-validation for matrix completion.</p> <p>Performs exhaustive grid search over specified parameter values with entry-wise cross-validation for symmetric matrices.</p> <p>Parameters:</p> Name Type Description Default <code>estimator</code> <code>BaseEstimator</code> <p>Model instance to optimize</p> required <code>param_grid</code> <code>dict</code> <p>Dictionary with parameter names as keys and lists of values to try</p> required <code>cv</code> <code>EntryMaskSplit</code> <p>Cross-validation splitter</p> required <code>n_jobs</code> <code>int</code> <p>Number of parallel jobs (-1 uses all processors)</p> <code>-1</code> <code>verbose</code> <code>int</code> <p>Verbosity level</p> <code>0</code> <code>fit_final_estimator</code> <code>bool</code> <p>Whether to fit the model on full data with best parameters</p> <code>False</code> <p>Attributes:</p> Name Type Description <code>best_params_</code> <code>dict</code> <p>Parameters that gave the best score</p> <code>best_score_</code> <code>float</code> <p>Best validation score achieved</p> <code>cv_results_</code> <code>DataFrame</code> <p>Detailed results for all parameter combinations</p> <code>best_estimator_</code> <code>estimator</code> <p>Fitted estimator with best parameters (if fit_final_estimator=True)</p> Source code in <code>pysrf/cross_validation.py</code> <pre><code>def __init__(\n    self,\n    estimator: BaseEstimator,\n    param_grid: dict[str, list],\n    cv: EntryMaskSplit,\n    n_jobs: int = -1,\n    verbose: int = 0,\n    fit_final_estimator: bool = False,\n):\n    self.estimator = estimator\n    self.param_grid = param_grid\n    self.cv = cv\n    self.n_jobs = n_jobs\n    self.verbose = verbose\n    self.fit_final_estimator = fit_final_estimator\n</code></pre>"},{"location":"api/cross_validation/#cv-strategy","title":"CV Strategy","text":""},{"location":"api/cross_validation/#pysrf.EntryMaskSplit","title":"EntryMaskSplit","text":"<pre><code>EntryMaskSplit(\n    n_repeats: int = 5,\n    sampling_fraction: float = 0.8,\n    random_state: int | None = None,\n    missing_values: float | None = np.nan,\n)\n</code></pre> <p>             Bases: <code>BaseCrossValidator</code></p> <p>Cross-validator for symmetric matrices using entry-wise splits.</p> <p>Generates multiple random train/validation splits by masking entries in a symmetric matrix while preserving symmetry.</p> <p>Parameters:</p> Name Type Description Default <code>n_repeats</code> <code>int</code> <p>Number of random splits to generate</p> <code>5</code> <code>sampling_fraction</code> <code>float</code> <p>Fraction of eligible entries kept for training; must be in (0, 1). Remaining (1 - sampling_fraction) becomes validation. Note: Constant diagonal entries are excluded from both.</p> <code>0.8</code> <code>random_state</code> <code>int or None</code> <p>Random seed for reproducibility</p> <code>None</code> <code>missing_values</code> <code>float or None</code> <p>Value that marks missing entries in original data</p> <code>np.nan</code> Source code in <code>pysrf/cross_validation.py</code> <pre><code>def __init__(\n    self,\n    n_repeats: int = 5,\n    sampling_fraction: float = 0.8,\n    random_state: int | None = None,\n    missing_values: float | None = np.nan,\n):\n    self.n_repeats = n_repeats\n    self.sampling_fraction = sampling_fraction\n    self.random_state = random_state\n    self.missing_values = missing_values\n    if not (0.0 &lt; float(self.sampling_fraction) &lt; 1.0):\n        raise ValueError(\"sampling_fraction must be in (0, 1)\")\n</code></pre>"},{"location":"api/cross_validation/#pysrf.EntryMaskSplit.split","title":"split","text":"<pre><code>split(\n    x: np.ndarray,\n    y: np.ndarray = None,\n    groups: np.ndarray = None,\n) -&gt; Generator[Tuple[np.ndarray, np.ndarray], None, None]\n</code></pre> <p>Generate train/validation splits.</p> <p>Yields:</p> Name Type Description <code>train_mask</code> <code>ndarray of bool</code> <p>Training entries (True = use for training)</p> <code>validation_mask</code> <code>ndarray of bool</code> <p>Validation entries (True = use for evaluation)</p> Source code in <code>pysrf/cross_validation.py</code> <pre><code>def split(\n    self, x: np.ndarray, y: np.ndarray = None, groups: np.ndarray = None\n) -&gt; Generator[Tuple[np.ndarray, np.ndarray], None, None]:\n    \"\"\"\n    Generate train/validation splits.\n\n    Yields\n    ------\n    train_mask : ndarray of bool\n        Training entries (True = use for training)\n    validation_mask : ndarray of bool\n        Validation entries (True = use for evaluation)\n    \"\"\"\n    rng = check_random_state(self.random_state)\n    for _ in range(self.n_repeats):\n        yield create_train_val_split(\n            x, self.sampling_fraction, rng, self.missing_values\n        )\n</code></pre>"},{"location":"api/cross_validation/#scoring","title":"Scoring","text":""},{"location":"api/cross_validation/#pysrf.cross_validation.fit_and_score","title":"fit_and_score","text":"<pre><code>fit_and_score(\n    estimator: BaseEstimator,\n    x: np.ndarray,\n    train_mask: np.ndarray,\n    validation_mask: np.ndarray,\n    fit_params: dict,\n    split_idx: int | None = None,\n) -&gt; dict\n</code></pre> <p>Fit estimator with parameters and return validation score.</p> <p>Parameters:</p> Name Type Description Default <code>estimator</code> <code>BaseEstimator</code> <p>Model instance to fit (works with SRF or any estimator with .reconstruct())</p> required <code>x</code> <code>ndarray</code> <p>Full data matrix</p> required <code>train_mask</code> <code>ndarray of bool</code> <p>Boolean mask where True = training entry</p> required <code>validation_mask</code> <code>ndarray of bool</code> <p>Boolean mask where True = validation entry</p> required <code>fit_params</code> <code>dict</code> <p>Parameters to set on the estimator</p> required <code>split_idx</code> <code>int or None</code> <p>Index of the CV split</p> <code>None</code> <p>Returns:</p> Name Type Description <code>result</code> <code>dict</code> <p>Dictionary with score, parameters, and fitted estimator</p> Source code in <code>pysrf/cross_validation.py</code> <pre><code>def fit_and_score(\n    estimator: BaseEstimator,\n    x: np.ndarray,\n    train_mask: np.ndarray,\n    validation_mask: np.ndarray,\n    fit_params: dict,\n    split_idx: int | None = None,\n) -&gt; dict:\n    \"\"\"\n    Fit estimator with parameters and return validation score.\n\n    Parameters\n    ----------\n    estimator : BaseEstimator\n        Model instance to fit (works with SRF or any estimator with .reconstruct())\n    x : ndarray\n        Full data matrix\n    train_mask : ndarray of bool\n        Boolean mask where True = training entry\n    validation_mask : ndarray of bool\n        Boolean mask where True = validation entry\n    fit_params : dict\n        Parameters to set on the estimator\n    split_idx : int or None\n        Index of the CV split\n\n    Returns\n    -------\n    result : dict\n        Dictionary with score, parameters, and fitted estimator\n    \"\"\"\n    est = clone(estimator).set_params(**fit_params)\n\n    # Set SRF-specific params if estimator supports them\n    if hasattr(est, \"missing_values\"):\n        est.set_params(missing_values=np.nan)\n\n    if hasattr(est, \"bounds\"):\n        if \"bounds\" not in fit_params or fit_params[\"bounds\"] is None:\n            original_bounds = (np.nanmin(x), np.nanmax(x))\n            est.set_params(bounds=original_bounds)\n\n    # Track which entries were already NaN in the original data\n    originally_nan = np.isnan(x)\n\n    # Create training data: keep only training entries, mask everything else\n    x_train = np.full_like(x, np.nan)\n    x_train[train_mask] = x[train_mask]\n\n    # Fit model on training data only\n    est.fit(x_train)\n\n    # Get reconstruction\n    if hasattr(est, \"reconstruct\"):\n        reconstruction = est.reconstruct()\n    else:\n        raise ValueError(\n            f\"Estimator {type(est).__name__} must have a .reconstruct() method \"\n            \"for matrix completion cross-validation\"\n        )\n\n    # Evaluate only on validation entries that were originally observed\n    valid_eval_mask = validation_mask &amp; ~originally_nan\n\n    if not valid_eval_mask.any():\n        raise ValueError(\"No valid validation entries to evaluate\")\n\n    mse = np.mean((x[valid_eval_mask] - reconstruction[valid_eval_mask]) ** 2)\n\n    result = {\n        \"score\": mse,\n        \"split\": split_idx if split_idx is not None else 0,\n        \"estimator\": est,\n        \"params\": fit_params,\n    }\n\n    # Include history if available (optional)\n    if hasattr(est, \"history_\"):\n        result[\"history\"] = est.history_\n\n    return result\n</code></pre>"},{"location":"api/model/","title":"Model API","text":""},{"location":"api/model/#srf-class","title":"SRF Class","text":""},{"location":"api/model/#pysrf.SRF","title":"SRF","text":"<pre><code>SRF(\n    rank: int = 10,\n    rho: float = 3.0,\n    max_outer: int = 30,\n    max_inner: int = 20,\n    tol: float = 0.0001,\n    verbose: int = 0,\n    init: str = \"random_sqrt\",\n    random_state: int | None = None,\n    missing_values: float | None = np.nan,\n    bounds: tuple[float, float] | None = (None, None),\n)\n</code></pre> <p>             Bases: <code>TransformerMixin</code>, <code>BaseEstimator</code></p> <p>Symmetric Non-negative Matrix Factorization using SRF.</p> <p>This class implements symmetric non-negative matrix factorization (SymNMF) using the Alternating Direction Method of Multipliers (SRF). It can handle missing entries and optional bound constraints on the factorization.</p> <p>The algorithm solves: min_{w&gt;=0,v} ||M o (S - v)||^2_F + rho/2 ||v - ww^T||^2_F subject to optional bounds on v, where M is an observation mask.</p> <p>Parameters:</p> Name Type Description Default <code>rank</code> <code>int</code> <p>Number of factors (dimensionality of the latent space)</p> <code>10</code> <code>rho</code> <code>float</code> <p>SRF penalty parameter controlling constraint enforcement</p> <code>3.0</code> <code>max_outer</code> <code>int</code> <p>Maximum number of SRF outer iterations</p> <code>10</code> <code>max_inner</code> <code>int</code> <p>Maximum iterations for w-subproblem per outer iteration</p> <code>30</code> <code>tol</code> <code>float</code> <p>Convergence tolerance for constraint violation</p> <code>1e-4</code> <code>verbose</code> <code>int</code> <p>Whether to print optimization progress</p> <code>0</code> <code>init</code> <code>str</code> <p>Method for factor initialization ('random', 'random_sqrt', 'nndsvd', 'nndsvdar', 'eigenspectrum')</p> <code>'random_sqrt'</code> <code>random_state</code> <code>int or None</code> <p>Random seed for reproducible initialization</p> <code>None</code> <code>missing_values</code> <code>float or None</code> <p>Values to be treated as missing to mask the matrix</p> <code>np.nan</code> <code>bounds</code> <code>tuple of (float, float) or None</code> <p>Tuple of (lower, upper) bounds for the auxiliary variable v. If None, the bounds are inferred from the data. In practice, one can also pass the expected bounds of the matrix (e.g. (0, 1) for cosine similarity)</p> <code>(None, None)</code> <p>Attributes:</p> Name Type Description <code>w_</code> <code>np.ndarray of shape (n_samples, rank)</code> <p>Learned factor matrix w</p> <code>components_</code> <code>np.ndarray of shape (n_samples, rank)</code> <p>Alias for w_ (sklearn compatibility)</p> <code>n_iter_</code> <code>int</code> <p>Number of SRF iterations performed</p> <code>history_</code> <code>dict</code> <p>Dictionary containing optimization metrics per iteration</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Basic usage with complete data\n&gt;&gt;&gt; from pysrf import SRF\n&gt;&gt;&gt; model = SRF(rank=10, random_state=42)\n&gt;&gt;&gt; w = model.fit_transform(similarity_matrix)\n&gt;&gt;&gt; reconstruction = w @ w.T\n</code></pre> <pre><code>&gt;&gt;&gt; # Usage with missing data (NaN values)\n&gt;&gt;&gt; similarity_matrix[mask] = np.nan\n&gt;&gt;&gt; model = SRF(rank=10, missing_values=np.nan)\n&gt;&gt;&gt; w = model.fit_transform(similarity_matrix)\n</code></pre> References <p>.. [1] Shi et al. (2016). \"Inexact Block Coordinate Descent Methods For        Symmetric Nonnegative Matrix Factorization\"</p> Source code in <code>pysrf/model.py</code> <pre><code>def __init__(\n    self,\n    rank: int = 10,\n    rho: float = 3.0,\n    max_outer: int = 30,\n    max_inner: int = 20,\n    tol: float = 1e-4,\n    verbose: int = 0,\n    init: str = \"random_sqrt\",\n    random_state: int | None = None,\n    missing_values: float | None = np.nan,\n    bounds: tuple[float, float] | None = (None, None),\n) -&gt; None:\n    self.rank = rank\n    self.rho = rho\n    self.max_outer = max_outer\n    self.max_inner = max_inner\n    self.tol = tol\n    self.verbose = verbose\n    self.init = init\n    self.random_state = random_state\n    self.missing_values = missing_values\n    self.bounds = bounds\n</code></pre>"},{"location":"api/model/#pysrf.SRF.fit","title":"fit","text":"<pre><code>fit(x: np.ndarray, y: np.ndarray | None = None) -&gt; SRF\n</code></pre> <p>Fit the symmetric NMF model to the data.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array-like of shape (n_samples, n_samples)</code> <p>Symmetric similarity matrix. Missing values are allowed and should be marked according to the missing_values parameter.</p> required <code>y</code> <code>Ignored</code> <p>Not used, present here for API consistency by convention.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>self</code> <code>object</code> <p>Fitted estimator.</p> Source code in <code>pysrf/model.py</code> <pre><code>def fit(self, x: np.ndarray, y: np.ndarray | None = None) -&gt; SRF:\n    \"\"\"\n    Fit the symmetric NMF model to the data.\n\n    Parameters\n    ----------\n    x : array-like of shape (n_samples, n_samples)\n        Symmetric similarity matrix. Missing values are allowed and should\n        be marked according to the missing_values parameter.\n    y : Ignored\n        Not used, present here for API consistency by convention.\n\n    Returns\n    -------\n    self : object\n        Fitted estimator.\n    \"\"\"\n    self._validate_params()\n    _validate_bounds(self.bounds)\n\n    x = validate_data(\n        self,\n        x,\n        reset=True,\n        ensure_all_finite=(\n            \"allow-nan\" if _is_nan_marker(self.missing_values) else True\n        ),\n        ensure_2d=True,\n        dtype=np.float64,\n        copy=True,\n    )\n\n    self._missing_mask = _get_missing_mask(x, self.missing_values)\n    if np.all(self._missing_mask):\n        raise ValueError(\n            \"No observed entries found in the data. All values are missing.\"\n        )\n\n    check_symmetric(self._missing_mask, raise_exception=True)\n    self._observation_mask = ~self._missing_mask\n    x[self._missing_mask] = 0.0\n    x = check_symmetric(x, raise_exception=True, tol=1e-10)\n\n    if np.all(self._observation_mask):\n        return self._fit_complete_data(x)\n    else:\n        return self._fit_missing_data(x)\n</code></pre>"},{"location":"api/model/#pysrf.SRF.fit_transform","title":"fit_transform","text":"<pre><code>fit_transform(\n    x: np.ndarray, y: np.ndarray | None = None\n) -&gt; np.ndarray\n</code></pre> <p>Fit the model and return the learned factors.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array-like of shape (n_samples, n_samples)</code> <p>Symmetric similarity matrix</p> required <code>y</code> <code>Ignored</code> <p>Not used, present here for API consistency by convention.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>w</code> <code>array-like of shape (n_samples, rank)</code> <p>Learned factor matrix</p> Source code in <code>pysrf/model.py</code> <pre><code>def fit_transform(self, x: np.ndarray, y: np.ndarray | None = None) -&gt; np.ndarray:\n    \"\"\"\n    Fit the model and return the learned factors.\n\n    Parameters\n    ----------\n    x : array-like of shape (n_samples, n_samples)\n        Symmetric similarity matrix\n    y : Ignored\n        Not used, present here for API consistency by convention.\n\n    Returns\n    -------\n    w : array-like of shape (n_samples, rank)\n        Learned factor matrix\n    \"\"\"\n    return self.fit(x, y).transform(x)\n</code></pre>"},{"location":"api/model/#pysrf.SRF.reconstruct","title":"reconstruct","text":"<pre><code>reconstruct(w: np.ndarray | None = None) -&gt; np.ndarray\n</code></pre> <p>Reconstruct the similarity matrix from factors.</p> <p>Parameters:</p> Name Type Description Default <code>w</code> <code>array-like of shape (n_samples, rank) or None</code> <p>Factor matrix to use for reconstruction. If None, uses the fitted factors.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>s_hat</code> <code>array-like of shape (n_samples, n_samples)</code> <p>Reconstructed similarity matrix</p> Source code in <code>pysrf/model.py</code> <pre><code>def reconstruct(self, w: np.ndarray | None = None) -&gt; np.ndarray:\n    \"\"\"\n    Reconstruct the similarity matrix from factors.\n\n    Parameters\n    ----------\n    w : array-like of shape (n_samples, rank) or None\n        Factor matrix to use for reconstruction.\n        If None, uses the fitted factors.\n\n    Returns\n    -------\n    s_hat : array-like of shape (n_samples, n_samples)\n        Reconstructed similarity matrix\n    \"\"\"\n    if w is None:\n        check_is_fitted(self)\n        w = self.w_\n\n    return w @ w.T\n</code></pre>"},{"location":"api/model/#pysrf.SRF.score","title":"score","text":"<pre><code>score(x: np.ndarray, y: np.ndarray | None = None) -&gt; float\n</code></pre> <p>Score the model using reconstruction error on observed entries only.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array-like of shape (n_samples, n_samples)</code> <p>Symmetric similarity matrix. Missing values are allowed and should be marked according to the missing_values parameter.</p> required <code>y</code> <code>Ignored</code> <p>Not used, present here for API consistency by convention.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>mse</code> <code>float</code> <p>Mean squared error of the reconstruction on observed entries.</p> Source code in <code>pysrf/model.py</code> <pre><code>def score(self, x: np.ndarray, y: np.ndarray | None = None) -&gt; float:\n    \"\"\"\n    Score the model using reconstruction error on observed entries only.\n\n    Parameters\n    ----------\n    x : array-like of shape (n_samples, n_samples)\n        Symmetric similarity matrix. Missing values are allowed and should\n        be marked according to the missing_values parameter.\n    y : Ignored\n        Not used, present here for API consistency by convention.\n\n    Returns\n    -------\n    mse : float\n        Mean squared error of the reconstruction on observed entries.\n    \"\"\"\n    check_is_fitted(self)\n\n    x = validate_data(\n        self,\n        x,\n        reset=False,\n        ensure_2d=True,\n        dtype=np.float64,\n        ensure_all_finite=\"allow-nan\" if self.missing_values is np.nan else True,\n    )\n    observation_mask = ~_get_missing_mask(x, self.missing_values)\n    reconstruction = self.reconstruct()\n    mse = np.mean((x[observation_mask] - reconstruction[observation_mask]) ** 2)\n    return -mse\n</code></pre>"},{"location":"api/model/#pysrf.SRF.transform","title":"transform","text":"<pre><code>transform(x: np.ndarray) -&gt; np.ndarray\n</code></pre> <p>Project data onto the learned factor space.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array-like of shape (n_samples, n_samples)</code> <p>Symmetric matrix to transform</p> required <p>Returns:</p> Name Type Description <code>w</code> <code>array-like of shape (n_samples, rank)</code> <p>Transformed data</p> Source code in <code>pysrf/model.py</code> <pre><code>def transform(self, x: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Project data onto the learned factor space.\n\n    Parameters\n    ----------\n    x : array-like of shape (n_samples, n_samples)\n        Symmetric matrix to transform\n\n    Returns\n    -------\n    w : array-like of shape (n_samples, rank)\n        Transformed data\n    \"\"\"\n    check_is_fitted(self)\n    return self.w_\n</code></pre>"}]}