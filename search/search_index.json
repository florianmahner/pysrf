{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"pysrf","text":"<p>Similarity-Based Representation Factorization (SRF) </p>"},{"location":"#overview","title":"Overview","text":"<p><code>pysrf</code> implements symmetric non-negative matrix factorization using the Alternating Direction Method of Multipliers (SRF). </p>"},{"location":"#installation","title":"Installation","text":"<p>See the Installation Guide for detailed instructions.</p>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>import numpy as np\nfrom pysrf import SRF\n\n# Your similarity matrix\ns = np.random.rand(100, 100)\ns = (s + s.T) / 2  # make symmetric\n\n# Fit model\nmodel = SRF(rank=10, max_outer=20, random_state=42)\nembedding = model.fit_transform(s)\n\n# Reconstruct\ns_reconstructed = model.reconstruct()\n</code></pre>"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li>Installation Guide - Setup instructions</li> <li>Examples - Usage examples and workflows</li> <li>Quick Start Guide - Detailed tutorials</li> <li>API Reference - Complete API documentation</li> <li>Development Guide - Contributing guidelines</li> </ul>"},{"location":"development/","title":"Development Guide","text":""},{"location":"development/#setup-development-environment","title":"Setup Development Environment","text":""},{"location":"development/#using-the-setup-script","title":"Using the Setup Script","text":"<p>The easiest way to set up the development environment:</p> <pre><code>chmod +x setup.sh\n./setup.sh\n</code></pre> <p>This script will: 1. Install <code>pyenv</code> (if not present) 2. Install Python 3.12.4 3. Install Poetry 4. Install all dependencies 5. Compile Cython extensions 6. Run tests</p>"},{"location":"development/#manual-setup","title":"Manual Setup","text":"<pre><code># Install poetry\ncurl -sSL https://install.python-poetry.org | python3 -\n\n# Install dependencies\npoetry install\n\n# Compile Cython extensions\nmake compile\n\n# Run tests\npoetry run pytest\n</code></pre>"},{"location":"development/#makefile-commands","title":"Makefile Commands","text":"<p>The project includes a Makefile for common development tasks:</p> <pre><code>make dev           # Install with dev dependencies + compile Cython\nmake compile       # Compile Cython extensions\nmake test          # Run test suite\nmake test-cov      # Run tests with coverage report\nmake lint          # Run linter (ruff)\nmake format        # Format code with ruff\nmake clean         # Remove build artifacts\nmake docs          # Build documentation\nmake docs-serve    # Serve documentation locally\n</code></pre>"},{"location":"development/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\nmake test\n\n# Run with coverage\nmake test-cov\n\n# Run specific test file\npoetry run pytest tests/test_model.py -v\n\n# Run specific test\npoetry run pytest tests/test_model.py::test_srf_fit_complete_data -v\n</code></pre>"},{"location":"development/#code-quality","title":"Code Quality","text":""},{"location":"development/#linting","title":"Linting","text":"<pre><code># Check code quality\nmake lint\n\n# Auto-format code\nmake format\n</code></pre>"},{"location":"development/#type-checking","title":"Type Checking","text":"<p>The codebase uses Python 3.10+ type hints:</p> <pre><code>from __future__ import annotations\n\ndef my_function(x: np.ndarray, rank: int = 10) -&gt; tuple[np.ndarray, float]:\n    ...\n</code></pre>"},{"location":"development/#cython-extensions","title":"Cython Extensions","text":"<p>The performance-critical inner loop is implemented in Cython (<code>_bsum.pyx</code>):</p> <pre><code># Compile Cython extensions\nmake compile\n\n# Or directly\npoetry run python setup.py build_ext --inplace\n</code></pre>"},{"location":"development/#testing-cython-vs-python","title":"Testing Cython vs Python","text":"<pre><code>from pysrf.model import _get_update_w_function\n\nupdate_w = _get_update_w_function()\nprint(f\"Using: {update_w.__module__}\")\n# Cython: _bsum\n# Python fallback: pysrf.model\n</code></pre>"},{"location":"development/#documentation","title":"Documentation","text":""},{"location":"development/#building-docs","title":"Building Docs","text":"<pre><code># Build documentation\nmake docs\n\n# Serve locally at http://127.0.0.1:8000\nmake docs-serve\n</code></pre>"},{"location":"development/#writing-docstrings","title":"Writing Docstrings","text":"<p>Use NumPy-style docstrings:</p> <pre><code>def my_function(x: np.ndarray, param: int = 10) -&gt; float:\n    \"\"\"\n    Brief description.\n\n    Longer description explaining the function's purpose and behavior.\n\n    Parameters\n    ----------\n    x : ndarray\n        Description of x\n    param : int, default=10\n        Description of param\n\n    Returns\n    -------\n    result : float\n        Description of return value\n\n    Examples\n    --------\n    &gt;&gt;&gt; result = my_function(np.array([1, 2, 3]))\n    &gt;&gt;&gt; print(result)\n    0.123\n    \"\"\"\n    ...\n</code></pre>"},{"location":"development/#contributing","title":"Contributing","text":""},{"location":"development/#workflow","title":"Workflow","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch: <code>git checkout -b feature-name</code></li> <li>Make your changes</li> <li>Run tests: <code>make test</code></li> <li>Format code: <code>make format</code></li> <li>Commit: <code>git commit -m \"Add feature\"</code></li> <li>Push: <code>git push origin feature-name</code></li> <li>Open a Pull Request</li> </ol>"},{"location":"development/#guidelines","title":"Guidelines","text":"<ul> <li>Write tests for new features</li> <li>Maintain type hints</li> <li>Update documentation</li> <li>Keep changes focused</li> <li>Follow existing code style</li> </ul>"},{"location":"development/#publishing","title":"Publishing","text":""},{"location":"development/#pypi-release","title":"PyPI Release","text":"<pre><code># Update version in pyproject.toml\npoetry version patch  # or minor, major\n\n# Build package\nmake build\n\n# Publish to PyPI\npoetry publish\n</code></pre>"},{"location":"development/#development-release","title":"Development Release","text":"<pre><code># Build with dev version\npoetry version prerelease\n\n# Publish to TestPyPI\npoetry publish -r testpypi\n</code></pre>"},{"location":"development/#project-structure","title":"Project Structure","text":"<pre><code>pysrf/\n\u251c\u2500\u2500 pysrf/              # Main package\n\u2502   \u251c\u2500\u2500 __init__.py    # Public API\n\u2502   \u251c\u2500\u2500 model.py       # SRF class\n\u2502   \u251c\u2500\u2500 cross_validation.py\n\u2502   \u251c\u2500\u2500 bounds.py      # Sampling bound estimation\n\u2502   \u251c\u2500\u2500 utils.py       # Helper functions\n\u2502   \u2514\u2500\u2500 _bsum.pyx      # Cython extension\n\u251c\u2500\u2500 tests/             # Test suite\n\u251c\u2500\u2500 docs/              # Documentation\n\u251c\u2500\u2500 setup.py           # Cython build (setuptools)\n\u251c\u2500\u2500 Makefile           # Development commands\n\u251c\u2500\u2500 pyproject.toml     # Poetry config\n\u2514\u2500\u2500 README.md          # Project overview\n</code></pre>"},{"location":"examples/","title":"Examples","text":""},{"location":"examples/#basic-usage","title":"Basic Usage","text":"<pre><code>import numpy as np\nfrom pysrf import SRF\n\n# Generate data\nn, rank = 100, 10\nw_true = np.random.rand(n, rank)\ns = w_true @ w_true.T\n\n# Fit model\nmodel = SRF(rank=10, random_state=42)\nw = model.fit_transform(s)\ns_hat = model.reconstruct()\n</code></pre>"},{"location":"examples/#handling-missing-data","title":"Handling Missing Data","text":"<pre><code>import numpy as np\nfrom pysrf import SRF\n\n# Generate data with missing entries\nn, rank = 100, 10\nw_true = np.random.rand(n, rank)\ns = w_true @ w_true.T\n\n# Mark missing entries\nmask = np.random.rand(n, n) &lt; 0.3\ns[mask] = np.nan\n\n# Fit model with missing data\nmodel = SRF(rank=10, missing_values=np.nan, random_state=42)\nw = model.fit_transform(s)\ns_completed = model.reconstruct()\n</code></pre>"},{"location":"examples/#cross-validation-for-rank-selection","title":"Cross-Validation for Rank Selection","text":"<pre><code>from pysrf import cross_val_score, SRF\n\n# Auto-estimate sampling fraction\ncv = cross_val_score(\n    s,\n    estimate_sampling_fraction=True,\n    param_grid={\"rank\": [5, 10, 15, 20]},\n    n_repeats=5,\n    n_jobs=-1,\n    random_state=42\n)\n\nprint(f\"Best rank: {cv.best_params_['rank']}\")\nprint(f\"Best score: {cv.best_score_:.4f}\")\n</code></pre>"},{"location":"examples/#ensemble-and-consensus-clustering","title":"Ensemble and Consensus Clustering","text":"<pre><code>from sklearn import pipeline\nfrom pysrf.consensus import EnsembleEmbedding, ClusterEmbedding\nfrom pysrf import SRF, cross_val_score\n\n# 1. Rank selection\ncv = cross_val_score(\n    s,\n    estimate_sampling_fraction=True,\n    param_grid={\"rank\": [5, 10, 15, 20]},\n    n_repeats=5,\n    n_jobs=-1,\n)\n\n# 2. Stable ensemble + consensus clustering\npipe = pipeline.Pipeline(\n    [\n        (\"ensemble\", EnsembleEmbedding(SRF(cv.best_params_), n_runs=50)),\n        (\"cluster\", ClusterEmbedding(min_clusters=2, max_clusters=6, step=1)),\n    ]\n)\n\nconsensus_embedding = pipe.fit_transform(s)\n</code></pre>"},{"location":"examples/#value-bounds","title":"Value Bounds","text":"<pre><code>from pysrf import SRF\n\n# Constrain reconstructed values to [0, 1] (e.g., for cosine similarity)\nmodel = SRF(rank=10, bounds=(0, 1), random_state=42)\nw = model.fit_transform(s)\ns_reconstructed = model.reconstruct()\n\n# Verify bounds\nassert s_reconstructed.min() &gt;= 0\nassert s_reconstructed.max() &lt;= 1\n</code></pre>"},{"location":"examples/#sampling-bound-estimation","title":"Sampling Bound Estimation","text":"<pre><code>from pysrf import estimate_sampling_bounds_fast\n\n# Estimate sampling rate bounds for reliable matrix completion\npmin, pmax, s_denoised = estimate_sampling_bounds_fast(\n    s,\n    n_jobs=-1,\n    random_state=42\n)\n\nprint(f\"Minimum sampling rate: {pmin:.4f}\")\nprint(f\"Maximum sampling rate: {pmax:.4f}\")\n\n# Use mid-point for cross-validation\nsampling_rate = 0.5 * (pmin + pmax)\n</code></pre>"},{"location":"examples/#complete-workflow","title":"Complete Workflow","text":"<pre><code>import numpy as np\nfrom pysrf import SRF, cross_val_score, estimate_sampling_bounds_fast\n\n# 1. Generate data\nnp.random.seed(42)\nn, true_rank = 100, 8\nw_true = np.random.rand(n, true_rank)\ns = w_true @ w_true.T\n\n# 2. Add noise and missing data\ns += 0.1 * np.random.randn(n, n)\ns = (s + s.T) / 2\nmask = np.random.rand(n, n) &lt; 0.2\ns[mask] = np.nan\n\n# 3. Estimate sampling bounds\npmin, pmax, _ = estimate_sampling_bounds_fast(s, n_jobs=-1)\nprint(f\"Sampling bounds: [{pmin:.3f}, {pmax:.3f}]\")\n\n# 4. Cross-validate to find best rank\nresult = cross_val_score(\n    s,\n    param_grid={'rank': range(5, 21)},\n    estimate_sampling_fraction=True,\n    n_repeats=3,\n    n_jobs=-1,\n    random_state=42\n)\nbest_rank = result.best_params_['rank']\nprint(f\"Best rank: {best_rank} (true rank: {true_rank})\")\n\n# 5. Fit final model\nmodel = SRF(rank=best_rank, max_outer=20, random_state=42)\nw = model.fit_transform(s)\ns_completed = model.reconstruct()\n\n# 6. Evaluate\nscore = model.score(s)\nprint(f\"Reconstruction error: {score:.4f}\")\n</code></pre>"},{"location":"installation/","title":"Installation","text":"<p>Cython Compilation</p> <p>For optimal performance (10-50x speedup), ensure Cython extensions are compiled during installation. You may need development tools installed.</p>"},{"location":"installation/#automated-setup-recommended","title":"Automated Setup (Recommended)","text":"<p>The easiest way to set up the complete development environment:</p> <pre><code>git clone https://github.com/fmahner/pysrf.git\ncd pysrf\n./setup.sh\n</code></pre> <p>This script will: 1. Check for and install <code>pyenv</code> (if missing) 2. Install <code>poetry</code> (if missing) 3. Install Python 3.12.4 via <code>pyenv</code> 4. Set the local Python version 5. Install all dependencies via <code>poetry</code> 6. Compile Cython extensions for 10-50x speedup 7. Run the test suite</p> <p>Activate the environment with <code>poetry shell</code>.</p>"},{"location":"installation/#manual-installation","title":"Manual Installation","text":"<p>If you prefer manual setup or need more control:</p>"},{"location":"installation/#step-1-install-prerequisites","title":"Step 1: Install Prerequisites","text":"<pre><code># Install pyenv (if not already installed)\ncurl https://pyenv.run | bash\n\n# Install poetry (if not already installed)\ncurl -sSL https://install.python-poetry.org | python3 -\n</code></pre>"},{"location":"installation/#step-2-set-up-python-environment","title":"Step 2: Set Up Python Environment","text":"<pre><code># Install Python 3.12.4 (or your preferred version &gt;=3.10)\npyenv install 3.12.4\npyenv local 3.12.4\n</code></pre>"},{"location":"installation/#step-3-install-dependencies","title":"Step 3: Install Dependencies","text":"<pre><code># Install dependencies with poetry\npoetry install\n</code></pre>"},{"location":"installation/#step-4-compile-cython-extensions","title":"Step 4: Compile Cython Extensions","text":"<p>Cython compilation is critical for performance (10-50x speedup). Without it, a pure Python fallback is used.</p> <pre><code># Using the Makefile\nmake compile\n\n# Or directly\npoetry run python setup.py build_ext --inplace\n</code></pre> <p>The Makefile also provides other useful commands: - <code>make dev</code> - Install with dev dependencies and compile - <code>make test</code> - Run test suite - <code>make format</code> - Format code - <code>make clean</code> - Remove build artifacts - <code>make docs</code> - Build documentation</p>"},{"location":"installation/#alternative-installation-methods","title":"Alternative Installation Methods","text":""},{"location":"installation/#from-pypi-future","title":"From PyPI (Future)","text":"<p>Once published to PyPI:</p> <pre><code># Stable release\npip install pysrf\n\n# Development version\npip install --pre pysrf\n</code></pre>"},{"location":"installation/#as-git-subtree-for-development-integration","title":"As Git Subtree (For Development Integration)","text":"<pre><code># Add as subtree in your project\ngit subtree add --prefix=pysrf https://github.com/fmahner/pysrf.git master --squash\n\n# Update subtree\ngit subtree pull --prefix=pysrf https://github.com/fmahner/pysrf.git master --squash\n\n# Install from subtree\ncd pysrf &amp;&amp; poetry install &amp;&amp; make compile\n</code></pre>"},{"location":"installation/#verify-installation","title":"Verify Installation","text":"<pre><code>import pysrf\nprint(pysrf.__version__)\n\n# Check Cython compilation\nfrom pysrf.model import _get_update_w_function\nupdate_w = _get_update_w_function()\nprint(f\"Using: {update_w.__module__}\")  # Should show _bsum if compiled\n</code></pre>"},{"location":"quickstart/","title":"Quick Start","text":""},{"location":"quickstart/#basic-usage","title":"Basic Usage","text":""},{"location":"quickstart/#factorize-a-symmetric-matrix","title":"Factorize a symmetric matrix","text":"<pre><code>import numpy as np\nfrom pysrf import SRF\n\n# Generate or load your similarity matrix\ns = np.random.rand(100, 100)\ns = (s + s.T) / 2  # ensure symmetry\n\n# Fit the model\nmodel = SRF(rank=10, max_outer=20, random_state=42)\nw = model.fit_transform(s)\n\n# Reconstruct the matrix\ns_reconstructed = model.reconstruct()\n# or equivalently: s_reconstructed = w @ w.T\n\n# Evaluate fit\nscore = model.score(s)\nprint(f\"Reconstruction error: {score:.4f}\")\n</code></pre>"},{"location":"quickstart/#handling-missing-data","title":"Handling Missing Data","text":"<pre><code>import numpy as np\nfrom pysrf import SRF\n\n# Matrix with missing values (NaN)\ns = np.random.rand(100, 100)\ns = (s + s.T) / 2\ns[np.random.rand(100, 100) &lt; 0.3] = np.nan  # 30% missing\n\n# Model handles missing data automatically\nmodel = SRF(rank=10, missing_values=np.nan, random_state=42)\nw = model.fit_transform(s)\ns_completed = model.reconstruct()\n</code></pre>"},{"location":"quickstart/#cross-validation-to-estimate-the-rank","title":"Cross-Validation to estimate the rank","text":""},{"location":"quickstart/#manual-sampling-fraction","title":"Manual Sampling Fraction","text":"<pre><code>from pysrf import cross_val_score\n\ns = np.random.rand(100, 100)\ns = (s + s.T) / 2\n\n# Define parameter grid\ncv = cross_val_score(s, param_grid = {'rank': [5, 10, 15, 20]})\n\nprint(f\"Best parameters: {result.best_params_}\")\nprint(f\"Best score: {result.best_score_:.4f}\")\n</code></pre>"},{"location":"api/bounds/","title":"Sampling Bounds API","text":""},{"location":"api/bounds/#main-functions","title":"Main Functions","text":""},{"location":"api/bounds/#pysrf.estimate_sampling_bounds_fast","title":"estimate_sampling_bounds_fast","text":"<pre><code>estimate_sampling_bounds_fast(\n    S: np.ndarray,\n    gamma: float = 1.05,\n    eta: float = 0.05,\n    rho: float = 0.95,\n    method: str = \"dyson\",\n    omega: float = 0.8,\n    eta_pmax: float = 0.001,\n    jump_frac: float = 0.1,\n    tol: float = 0.0001,\n    gap: float = 0.05,\n    random_state: int = 31213,\n    n_jobs: int = -1,\n) -&gt; tuple[float, float, np.ndarray]\n</code></pre> Source code in <code>pysrf/bounds.py</code> <pre><code>def estimate_sampling_bounds_fast(\n    S: np.ndarray,\n    gamma: float = 1.05,\n    eta: float = 0.05,\n    rho: float = 0.95,\n    method: str = \"dyson\",\n    omega: float = 0.8,\n    eta_pmax: float = 1e-3,\n    jump_frac: float = 0.1,\n    tol: float = 1e-4,\n    gap: float = 0.05,\n    random_state: int = 31213,\n    n_jobs: int = -1,\n) -&gt; tuple[float, float, np.ndarray]:\n    pmin, _, _, _, _ = pmin_bound(\n        S, gamma=gamma, eta=eta, rho=rho, random_state=random_state,\n    )\n\n    eff_dim = np.ceil((np.linalg.norm(S, \"fro\") / np.linalg.norm(S, 2)) ** 2).astype(\n        int\n    )\n\n    pmax = p_upper_only_k(\n        S,\n        k=eff_dim,\n        method=method,\n        tol=tol,\n        omega=omega,\n        eta=eta_pmax,\n        jump_frac=jump_frac,\n        seed=random_state,\n    )\n\n    S_noise = S\n\n    if pmin &gt; pmax - gap:\n        epsilon = np.linalg.norm(S, 2) / np.sqrt(S.shape[0])\n        t_range = np.linspace(0.0, epsilon, 10)\n\n        A = np.random.rand(S.shape[0], S.shape[1])\n        AtA = A + A.T\n\n        def _eval_t(t):\n            S_t = S + t * AtA\n            pmin_t, _, _, _, _ = pmin_bound(\n                S_t,\n                gamma=gamma,\n                eta=eta,\n                rho=rho,\n                random_state=random_state,\n            )\n            eff_dim_t = np.ceil(\n                (np.linalg.norm(S_t, \"fro\") / np.linalg.norm(S_t, 2)) ** 2\n            ).astype(int)\n            pmax_t = p_upper_only_k(\n                S_t,\n                k=eff_dim_t,\n                method=method,\n                tol=tol,\n                omega=omega,\n                eta=eta_pmax,\n                jump_frac=jump_frac,\n                seed=random_state,\n            )\n            return float(pmin_t), float(pmax_t)\n\n        results = Parallel(n_jobs=n_jobs)(delayed(_eval_t)(float(t)) for t in t_range)\n\n        idx = None\n        for i, (pm, px) in enumerate(results):\n            if pm &lt; px - gap:\n                idx = i\n                break\n\n        if idx is not None:\n            t_threshold = float(t_range[idx])\n            pmin, pmax = results[idx]\n        else:\n            t_threshold = 0.0\n            pmin, pmax = results[-1]\n\n        S_noise = S + t_threshold * AtA\n\n    return pmin, pmax, S_noise\n</code></pre>"},{"location":"api/bounds/#pysrf.estimate_sampling_bounds","title":"estimate_sampling_bounds","text":"<pre><code>estimate_sampling_bounds(\n    S: np.ndarray,\n    gamma: float = 1.05,\n    eta: float = 0.05,\n    rho: float = 0.95,\n    method: str = \"dyson\",\n    omega: float = 0.8,\n    eta_pmax: float = 0.001,\n    jump_frac: float = 0.1,\n    tol: float = 0.0001,\n    gap: float = 0.05,\n    random_state: int = 31213,\n) -&gt; tuple[float, float, np.ndarray]\n</code></pre> Source code in <code>pysrf/bounds.py</code> <pre><code>def estimate_sampling_bounds(\n    S: np.ndarray,\n    gamma: float = 1.05,\n    eta: float = 0.05,\n    rho: float = 0.95,\n    method: str = \"dyson\",\n    omega: float = 0.8,\n    eta_pmax: float = 1e-3,\n    jump_frac: float = 0.1,\n    tol: float = 1e-4,\n    gap: float = 0.05,\n    random_state: int = 31213,\n) -&gt; tuple[float, float, np.ndarray]:\n    pmin, _, _, _, _ = pmin_bound(\n        S, gamma=gamma, eta=eta, rho=rho, random_state=random_state,\n    )\n\n    eff_dim = np.ceil((np.linalg.norm(S, \"fro\") / np.linalg.norm(S, 2)) ** 2).astype(\n        int\n    )\n\n    pmax = p_upper_only_k(\n        S,\n        k=eff_dim,\n        method=method,\n        tol=tol,\n        omega=omega,\n        eta=eta_pmax,\n        jump_frac=jump_frac,\n        seed=random_state,\n    )\n\n    S_noise = S\n\n    if pmin &gt; pmax - gap:\n        logger.info(\"Noise regime triggered, pmin=%.4f, pmax=%.4f\", pmin, pmax)\n\n        epsilon = np.linalg.norm(S, 2) / np.sqrt(S.shape[0])\n\n        t_range = np.linspace(0.0, epsilon, 10)\n        eff_dim_list = []\n        pmin_list = []\n        pmax_list = []\n\n        A = np.random.rand(S.shape[0], S.shape[1])\n\n        t_threshold = 0\n\n        t_iter = iter(t_range)\n        t = next(t_iter)\n\n        while True:\n            S_noise = S + t * (A + A.T)\n\n            pmin, _, _, _, _ = pmin_bound(\n                S_noise,\n                gamma=gamma,\n                eta=eta,\n                rho=rho,\n                random_state=random_state,\n            )\n\n            eff_dim = np.ceil(\n                (np.linalg.norm(S_noise, \"fro\") / np.linalg.norm(S_noise, 2)) ** 2\n            ).astype(int)\n            pmax = p_upper_only_k(\n                S_noise,\n                k=eff_dim,\n                method=method,\n                tol=tol,\n                omega=omega,\n                eta=eta_pmax,\n                jump_frac=jump_frac,\n                seed=random_state,\n            )\n            logger.info(\"t=%.4f, pmin=%.4f, eff_dim=%d, pmax=%.4f\", t, pmin, eff_dim, pmax)\n\n            eff_dim_list.append(eff_dim)\n            pmin_list.append(pmin)\n            pmax_list.append(pmax)\n\n            if pmin &lt; pmax - gap:\n                t_threshold = t\n                break\n\n            try:\n                t = next(t_iter)\n            except StopIteration:\n                break\n\n        S_noise = S + t_threshold * (A + A.T)\n\n    return pmin, pmax, S_noise\n</code></pre>"},{"location":"api/bounds/#lower-bound-estimation","title":"Lower Bound Estimation","text":""},{"location":"api/bounds/#pysrf.pmin_bound","title":"pmin_bound","text":"<pre><code>pmin_bound(\n    S: np.ndarray,\n    gamma: float = 1.05,\n    eta: float = 0.05,\n    rho: float = 0.95,\n    n_realizations: int = 500,\n    random_state: int | None = None,\n    monte_carlo: bool = False,\n) -&gt; tuple[float, float, float, float, np.ndarray]\n</code></pre> Source code in <code>pysrf/bounds.py</code> <pre><code>def pmin_bound(\n    S: np.ndarray,\n    gamma: float = 1.05,\n    eta: float = 0.05,\n    rho: float = 0.95,\n    n_realizations: int = 500,\n    random_state: int | None = None,\n    monte_carlo: bool = False,\n) -&gt; tuple[float, float, float, float, np.ndarray]:\n    np.random.seed(random_state)\n    n = S.shape[0]\n    _is_symmetric = np.allclose(S, S.T)\n\n    L_max = np.max((S**2).sum(axis=1) - np.diag(S) ** 2)\n\n    _row_sq = (S**2).sum(axis=1) - np.diag(S) ** 2\n    empirical_L_max = np.quantile(_row_sq, rho)\n\n    S_norm = np.linalg.norm(S, 2)\n\n    L_infty = 2 * np.max(np.abs(S))\n    empirical_L_infty = 2 * np.quantile(np.abs(S), rho)\n\n    effective_dimension = (np.linalg.norm(S, \"fro\") / S_norm) ** 2\n    logger.info(\"effective dimension: %s\", effective_dimension)\n\n    MC_expected_MS_norms = np.zeros(n_realizations)\n    if monte_carlo:\n        for i in range(n_realizations):\n            _p = np.random.rand()\n            _mask = np.random.binomial(1, _p, size=S.shape)\n            if _is_symmetric:\n                _mask = np.triu(_mask, 1)\n                _mask += _mask.T\n            MC_expected_MS_norms[i] = np.linalg.norm(_mask * S, 2)\n\n    N_bernstein = (gamma * L_infty * S_norm) / (3 * L_max) + 1\n    N_empirical = (gamma * empirical_L_infty * S_norm) / (3 * empirical_L_max) + 1\n    N_empirical_alternative = (gamma * L_infty * S_norm) / (3 * empirical_L_max) + 1\n    N_theory_upperbound = (gamma * S_norm) / 3 + 1\n\n    D_bernstein = ((gamma * S_norm) ** 2 / (2 * L_max) + 1) / np.log(2 * n / eta)\n    D_empirical = ((gamma * S_norm) ** 2 / (2 * empirical_L_max) + 1) / np.log(\n        2 * effective_dimension / eta\n    )\n    D_theory_lowerbound = ((gamma**2 * S_norm) / (2 * empirical_L_max) + 1) / np.log(\n        2 * n / eta\n    )\n\n    logger.info(\n        \"N_bernstein=%.4f, D_bernstein=%.4f, N_empirical=%.4f, D_empirical=%.4f, \"\n        \"N_empirical_alt=%.4f, N_theory_ub=%.4f, D_theory_lb=%.4f\",\n        N_bernstein, D_bernstein, N_empirical, D_empirical,\n        N_empirical_alternative, N_theory_upperbound, D_theory_lowerbound,\n    )\n\n    p_min = N_bernstein / D_bernstein\n    p_min_empirical = N_empirical / D_empirical\n    p_min_empirical_alternative = N_empirical_alternative / D_empirical\n    p_min_lowerbound = N_theory_upperbound / D_theory_lowerbound\n\n    logger.info(\n        \"p_min=%.4f, empirical_p_min=%.4f, empirical_p_min_alt=%.4f, theory_p_min=%.4f\",\n        p_min, p_min_empirical, p_min_empirical_alternative, p_min_lowerbound,\n    )\n\n    return (\n        p_min_empirical,\n        p_min,\n        p_min_lowerbound,\n        p_min_empirical_alternative,\n        MC_expected_MS_norms,\n    )\n</code></pre>"},{"location":"api/bounds/#upper-bound-estimation","title":"Upper Bound Estimation","text":""},{"location":"api/bounds/#pysrf.p_upper_only_k","title":"p_upper_only_k","text":"<pre><code>p_upper_only_k(\n    S: np.ndarray,\n    k: int = 1,\n    method: str = \"dyson\",\n    mc_trials: int = 600,\n    mc_quantile: float = 0.9,\n    tol: float = 0.0001,\n    seed: int | None = None,\n    omega: float = 0.8,\n    eta: float = 0.001,\n    jump_frac: float = 0.1,\n) -&gt; float\n</code></pre> Source code in <code>pysrf/bounds.py</code> <pre><code>def p_upper_only_k(\n    S: np.ndarray,\n    k: int = 1,\n    method: str = \"dyson\",\n    mc_trials: int = 600,\n    mc_quantile: float = 0.9,\n    tol: float = 1e-4,\n    seed: int | None = None,\n    omega: float = 0.8,\n    eta: float = 1e-3,\n    jump_frac: float = 0.1,\n) -&gt; float:\n    lam = np.sort(eigvalsh(S))[::-1]\n    n = len(lam)\n    if not (1 &lt;= k &lt;= n):\n        raise ValueError(\"k must be between 1 and n\")\n    lam_k = lam[k - 1]\n    lam_k1 = lam[k] if k &lt; n else None\n\n    if lam_k &lt;= 0:\n        logger.info(\"lambda_k &lt;= 0 -&gt; no positive spike to separate.\")\n        return 0.0\n    if (lam_k1 is None) or (lam_k1 &lt;= 0):\n        logger.info(\"lambda_{k+1} &lt;= 0 -&gt; only first k can be out for all large p; return 1.0.\")\n        return 1.0\n\n    edge = (\n        (\n            lambda p: lambda_bulk_dyson_raw(\n                S, p, omega=omega, eta=eta, jump_frac=jump_frac\n            )\n        )\n        if method == \"dyson\"\n        else (\n            lambda p: monte_carlo_bulk_edge_raw(\n                S, p, n_trials=mc_trials, quantile=mc_quantile, seed=seed\n            )\n        )\n    )\n\n    def count_out(p):\n        e = edge(p)\n        return int(np.sum(p * lam &gt; e)), e\n\n    c_hi, e_hi = count_out(0.99)\n    logger.info(\n        \"[sanity] p=0.99: bulk=%.4g, count_out=%d, lambda1=%.4g, lambda2=%.4g\",\n        e_hi, c_hi, lam[0], lam[1] if n &gt; 1 else np.nan,\n    )\n\n    if c_hi &lt; k:\n        logger.info(\"Even at p~1, only %d spikes out (&lt; k). Returning 1.0.\", c_hi)\n        return 1.0\n\n    grid = np.linspace(0.02, 0.99, 80)\n    feas = [p for p in grid if count_out(p)[0] == k]\n    if not feas:\n\n        def g(p):\n            return p * lam_k1 - edge(p)\n\n        a, b = 1e-3, 0.99\n        ga, gb = g(a), g(b)\n\n        if ga &gt;= 0 and gb &gt;= 0:\n            logger.info(\"(k+1) spike is out for all p; returning smallest p where count==k (none found) -&gt; 0.\")\n            return 0.0\n\n        if ga &lt; 0 and gb &lt;= 0:\n            logger.info(\"(k+1) never emerges up to 0.99; returning 1.0.\")\n            return 1.0\n\n        lo, hi = a, b\n        for _ in range(60):\n            mid = 0.5 * (lo + hi)\n            if g(mid) &gt;= 0:\n                hi = mid\n            else:\n                lo = mid\n            if (hi - lo) &lt; tol:\n                break\n\n        p_star = max(0.0, min(1.0, lo - 2 * tol))\n\n        return p_star\n\n    p_lo = max(feas)\n\n    def cond_ge_kplus1(p):\n        return count_out(p)[0] &gt;= (k + 1)\n\n    p_hi = min(0.99, p_lo + 0.05)\n    while (p_hi &lt; 0.99) and (not cond_ge_kplus1(p_hi)):\n        p_hi = min(0.99, p_hi + 0.05)\n    if not cond_ge_kplus1(p_hi):\n        return 1.0\n    lo, hi = p_lo, p_hi\n    for _ in range(60):\n        mid = 0.5 * (lo + hi)\n        if cond_ge_kplus1(mid):\n            hi = mid\n        else:\n            lo = mid\n        if (hi - lo) &lt; tol:\n            break\n    p_star = max(0.0, min(1.0, lo))\n    c_star, e_star = count_out(p_star)\n    logger.info(\"p*=%.4f, bulk=%.6g, count_out(p*)=%d\", p_star, e_star, c_star)\n    return p_star\n</code></pre>"},{"location":"api/cross_validation/","title":"Cross-Validation API","text":""},{"location":"api/cross_validation/#pysrf.cross_val_score","title":"cross_val_score","text":"<pre><code>cross_val_score(\n    similarity_matrix: np.ndarray,\n    estimator: BaseEstimator | None = None,\n    param_grid: dict[str, list] | None = None,\n    n_repeats: int = 5,\n    sampling_fraction: float = 0.8,\n    estimate_sampling_fraction: bool | dict = False,\n    sampling_selection: str = \"mean\",\n    random_state: int = 0,\n    verbose: int = 1,\n    n_jobs: int = -1,\n    missing_values: float | None = np.nan,\n    fit_final_estimator: bool = False,\n) -&gt; GridSearchCV\n</code></pre> <p>Cross-validate any estimator for matrix completion.</p> <p>Generic cross-validation function that works with SRF or any sklearn-compatible estimator with a .reconstruct() method.</p> <p>Parameters:</p> Name Type Description Default <code>similarity_matrix</code> <code>ndarray</code> <p>Symmetric similarity matrix to cross-validate</p> required <code>estimator</code> <code>BaseEstimator or None</code> <p>Estimator to cross-validate. If None, uses SRF(random_state=random_state). Can be a single estimator or a Pipeline. Must have a .reconstruct() method.</p> <code>None</code> <code>param_grid</code> <code>dict or None</code> <p>Dictionary with parameter names (str) as keys and lists of values to try as values. If None, uses default {'rank': [5, 10, 15, 20]} for SRF.</p> <code>None</code> <code>n_repeats</code> <code>int</code> <p>Number of times to repeat the cross-validation</p> <code>5</code> <code>sampling_fraction</code> <code>float</code> <p>Fraction of eligible entries to use for training in each split; must be in (0, 1). The remaining (1 - sampling_fraction) becomes validation. Note: Constant diagonal entries are excluded from both train and validation. Ignored when estimate_sampling_fraction is True or a dict; if both are provided, estimate_sampling_fraction takes precedence.</p> <code>0.8</code> <code>estimate_sampling_fraction</code> <code>bool or dict</code> <p>If True, automatically estimate optimal sampling fraction using sampling bound estimation from Random Matrix Theory. If dict, passed as kwargs to estimate_sampling_bounds_fast(). When enabled, overrides sampling_fraction.</p> <code>False</code> <code>sampling_selection</code> <code>str</code> <p>Selection method for the estimated sampling fraction; one of {\"mean\", \"min\", \"max\"}.</p> <code>\"mean\"</code> <code>random_state</code> <code>int</code> <p>Random seed for reproducibility</p> <code>0</code> <code>verbose</code> <code>int</code> <p>Verbosity level</p> <code>1</code> <code>n_jobs</code> <code>int</code> <p>Number of jobs to run in parallel (-1 uses all processors)</p> <code>-1</code> <code>missing_values</code> <code>float or None</code> <p>Value to consider as missing in original data</p> <code>np.nan</code> <code>fit_final_estimator</code> <code>bool</code> <p>Whether to fit the final estimator on the best parameters</p> <code>False</code> <p>Returns:</p> Name Type Description <code>grid</code> <code>GridSearchCV</code> <p>Fitted GridSearchCV object with best parameters and scores</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from pysrf.cross_validation import cross_val_score\n&gt;&gt;&gt; result = cross_val_score(similarity_matrix, param_grid={'rank': [5, 10, 15]})\n</code></pre> Source code in <code>pysrf/cross_validation.py</code> <pre><code>def cross_val_score(\n    similarity_matrix: np.ndarray,\n    estimator: BaseEstimator | None = None,\n    param_grid: dict[str, list] | None = None,\n    n_repeats: int = 5,\n    sampling_fraction: float = 0.8,\n    estimate_sampling_fraction: bool | dict = False,\n    sampling_selection: str = \"mean\",\n    random_state: int = 0,\n    verbose: int = 1,\n    n_jobs: int = -1,\n    missing_values: float | None = np.nan,\n    fit_final_estimator: bool = False,\n) -&gt; GridSearchCV:\n    \"\"\"\n    Cross-validate any estimator for matrix completion.\n\n    Generic cross-validation function that works with SRF or any sklearn-compatible\n    estimator with a .reconstruct() method.\n\n    Parameters\n    ----------\n    similarity_matrix : ndarray\n        Symmetric similarity matrix to cross-validate\n    estimator : BaseEstimator or None, default=None\n        Estimator to cross-validate. If None, uses SRF(random_state=random_state).\n        Can be a single estimator or a Pipeline. Must have a .reconstruct() method.\n    param_grid : dict or None, default=None\n        Dictionary with parameter names (str) as keys and lists of values to try\n        as values. If None, uses default {'rank': [5, 10, 15, 20]} for SRF.\n    n_repeats : int, default=5\n        Number of times to repeat the cross-validation\n    sampling_fraction : float, default=0.8\n        Fraction of eligible entries to use for training in each split; must be in (0, 1).\n        The remaining (1 - sampling_fraction) becomes validation.\n        Note: Constant diagonal entries are excluded from both train and validation.\n        Ignored when estimate_sampling_fraction is True or a dict; if both are provided,\n        estimate_sampling_fraction takes precedence.\n    estimate_sampling_fraction : bool or dict, default=False\n        If True, automatically estimate optimal sampling fraction using sampling\n        bound estimation from Random Matrix Theory. If dict, passed as kwargs to\n        estimate_sampling_bounds_fast(). When enabled, overrides sampling_fraction.\n    sampling_selection : str, default=\"mean\"\n        Selection method for the estimated sampling fraction; one of {\"mean\", \"min\", \"max\"}.\n    random_state : int, default=0\n        Random seed for reproducibility\n    verbose : int, default=1\n        Verbosity level\n    n_jobs : int, default=-1\n        Number of jobs to run in parallel (-1 uses all processors)\n    missing_values : float or None, default=np.nan\n        Value to consider as missing in original data\n    fit_final_estimator : bool, default=False\n        Whether to fit the final estimator on the best parameters\n\n    Returns\n    -------\n    grid : GridSearchCV\n        Fitted GridSearchCV object with best parameters and scores\n\n    Examples\n    --------\n    &gt;&gt;&gt; from pysrf.cross_validation import cross_val_score\n    &gt;&gt;&gt; result = cross_val_score(similarity_matrix, param_grid={'rank': [5, 10, 15]})\n    \"\"\"\n    if estimator is None:\n        estimator = SRF(random_state=random_state)\n\n    if param_grid is None:\n        param_grid = {\"rank\": [5, 10, 15, 20]}\n\n    valid_selections = {\"mean\", \"min\", \"max\"}\n    if sampling_selection not in valid_selections:\n        raise ValueError(\n            f\"sampling_selection must be one of {sorted(valid_selections)}\"\n        )\n\n    if estimate_sampling_fraction:\n        from .bounds import estimate_sampling_bounds_fast\n\n        kwargs = (\n            estimate_sampling_fraction\n            if isinstance(estimate_sampling_fraction, dict)\n            else {}\n        )\n        if \"random_state\" not in kwargs:\n            kwargs[\"random_state\"] = random_state\n        if \"n_jobs\" not in kwargs:\n            kwargs[\"n_jobs\"] = n_jobs\n        kwargs.pop(\"verbose\", None)\n\n        pmin, pmax, s_noise = estimate_sampling_bounds_fast(similarity_matrix, **kwargs)\n        sampling_fraction = {\n            \"mean\": np.mean([pmin, pmax]),\n            \"min\": pmin,\n            \"max\": pmax,\n        }[sampling_selection]\n\n    else:\n        _validate_sampling_fraction(sampling_fraction)\n\n    cv = EntryMaskSplit(\n        n_repeats=n_repeats,\n        sampling_fraction=sampling_fraction,\n        random_state=random_state,\n        missing_values=missing_values,\n    )\n    grid = GridSearchCV(\n        estimator=estimator,\n        param_grid=param_grid,\n        cv=cv,\n        n_jobs=n_jobs,\n        verbose=verbose,\n        fit_final_estimator=fit_final_estimator,\n    )\n    grid.fit(similarity_matrix)\n\n    return grid\n</code></pre>"},{"location":"api/cross_validation/#grid-search","title":"Grid Search","text":""},{"location":"api/cross_validation/#pysrf.GridSearchCV","title":"GridSearchCV","text":"<pre><code>GridSearchCV(\n    estimator: BaseEstimator,\n    param_grid: dict[str, list],\n    cv: EntryMaskSplit,\n    n_jobs: int = -1,\n    verbose: int = 0,\n    fit_final_estimator: bool = False,\n)\n</code></pre> <p>Grid search cross-validation for matrix completion.</p> <p>Performs exhaustive grid search over specified parameter values with entry-wise cross-validation for symmetric matrices.</p> <p>Parameters:</p> Name Type Description Default <code>estimator</code> <code>BaseEstimator</code> <p>Model instance to optimize</p> required <code>param_grid</code> <code>dict</code> <p>Dictionary with parameter names as keys and lists of values to try</p> required <code>cv</code> <code>EntryMaskSplit</code> <p>Cross-validation splitter</p> required <code>n_jobs</code> <code>int</code> <p>Number of parallel jobs (-1 uses all processors)</p> <code>-1</code> <code>verbose</code> <code>int</code> <p>Verbosity level</p> <code>0</code> <code>fit_final_estimator</code> <code>bool</code> <p>Whether to fit the model on full data with best parameters</p> <code>False</code> <p>Attributes:</p> Name Type Description <code>best_params_</code> <code>dict</code> <p>Parameters that gave the best score</p> <code>best_score_</code> <code>float</code> <p>Best validation score achieved</p> <code>cv_results_</code> <code>DataFrame</code> <p>Detailed results for all parameter combinations</p> <code>best_estimator_</code> <code>estimator</code> <p>Fitted estimator with best parameters (if fit_final_estimator=True)</p> Source code in <code>pysrf/cross_validation.py</code> <pre><code>def __init__(\n    self,\n    estimator: BaseEstimator,\n    param_grid: dict[str, list],\n    cv: EntryMaskSplit,\n    n_jobs: int = -1,\n    verbose: int = 0,\n    fit_final_estimator: bool = False,\n):\n    self.estimator = estimator\n    self.param_grid = param_grid\n    self.cv = cv\n    self.n_jobs = n_jobs\n    self.verbose = verbose\n    self.fit_final_estimator = fit_final_estimator\n</code></pre>"},{"location":"api/cross_validation/#cv-strategy","title":"CV Strategy","text":""},{"location":"api/cross_validation/#pysrf.EntryMaskSplit","title":"EntryMaskSplit","text":"<pre><code>EntryMaskSplit(\n    n_repeats: int = 5,\n    sampling_fraction: float = 0.8,\n    random_state: int | None = None,\n    missing_values: float | None = np.nan,\n)\n</code></pre> <p>             Bases: <code>BaseCrossValidator</code></p> <p>Cross-validator for symmetric matrices using entry-wise splits.</p> <p>Generates multiple random train/validation splits by masking entries in a symmetric matrix while preserving symmetry.</p> <p>Parameters:</p> Name Type Description Default <code>n_repeats</code> <code>int</code> <p>Number of random splits to generate</p> <code>5</code> <code>sampling_fraction</code> <code>float</code> <p>Fraction of eligible entries kept for training; must be in (0, 1). Remaining (1 - sampling_fraction) becomes validation. Note: Constant diagonal entries are excluded from both.</p> <code>0.8</code> <code>random_state</code> <code>int or None</code> <p>Random seed for reproducibility</p> <code>None</code> <code>missing_values</code> <code>float or None</code> <p>Value that marks missing entries in original data</p> <code>np.nan</code> Source code in <code>pysrf/cross_validation.py</code> <pre><code>def __init__(\n    self,\n    n_repeats: int = 5,\n    sampling_fraction: float = 0.8,\n    random_state: int | None = None,\n    missing_values: float | None = np.nan,\n):\n    self.n_repeats = n_repeats\n    self.sampling_fraction = sampling_fraction\n    self.random_state = random_state\n    self.missing_values = missing_values\n    if not (0.0 &lt; float(self.sampling_fraction) &lt; 1.0):\n        raise ValueError(\"sampling_fraction must be in (0, 1)\")\n</code></pre>"},{"location":"api/cross_validation/#pysrf.EntryMaskSplit.split","title":"split","text":"<pre><code>split(\n    x: np.ndarray,\n    y: np.ndarray = None,\n    groups: np.ndarray = None,\n) -&gt; Generator[Tuple[np.ndarray, np.ndarray], None, None]\n</code></pre> <p>Generate train/validation splits.</p> <p>Yields:</p> Name Type Description <code>train_mask</code> <code>ndarray of bool</code> <p>Training entries (True = use for training)</p> <code>validation_mask</code> <code>ndarray of bool</code> <p>Validation entries (True = use for evaluation)</p> Source code in <code>pysrf/cross_validation.py</code> <pre><code>def split(\n    self, x: np.ndarray, y: np.ndarray = None, groups: np.ndarray = None\n) -&gt; Generator[Tuple[np.ndarray, np.ndarray], None, None]:\n    \"\"\"\n    Generate train/validation splits.\n\n    Yields\n    ------\n    train_mask : ndarray of bool\n        Training entries (True = use for training)\n    validation_mask : ndarray of bool\n        Validation entries (True = use for evaluation)\n    \"\"\"\n    rng = check_random_state(self.random_state)\n    for _ in range(self.n_repeats):\n        yield create_train_val_split(\n            x, self.sampling_fraction, rng, self.missing_values\n        )\n</code></pre>"},{"location":"api/cross_validation/#scoring","title":"Scoring","text":""},{"location":"api/cross_validation/#pysrf.cross_validation.fit_and_score","title":"fit_and_score","text":"<pre><code>fit_and_score(\n    estimator: BaseEstimator,\n    x: np.ndarray,\n    train_mask: np.ndarray,\n    validation_mask: np.ndarray,\n    fit_params: dict,\n    split_idx: int | None = None,\n) -&gt; dict\n</code></pre> <p>Fit estimator with parameters and return validation score.</p> <p>Parameters:</p> Name Type Description Default <code>estimator</code> <code>BaseEstimator</code> <p>Model instance to fit (works with SRF or any estimator with .reconstruct())</p> required <code>x</code> <code>ndarray</code> <p>Full data matrix</p> required <code>train_mask</code> <code>ndarray of bool</code> <p>Boolean mask where True = training entry</p> required <code>validation_mask</code> <code>ndarray of bool</code> <p>Boolean mask where True = validation entry</p> required <code>fit_params</code> <code>dict</code> <p>Parameters to set on the estimator</p> required <code>split_idx</code> <code>int or None</code> <p>Index of the CV split</p> <code>None</code> <p>Returns:</p> Name Type Description <code>result</code> <code>dict</code> <p>Dictionary with score, parameters, and fitted estimator</p> Source code in <code>pysrf/cross_validation.py</code> <pre><code>def fit_and_score(\n    estimator: BaseEstimator,\n    x: np.ndarray,\n    train_mask: np.ndarray,\n    validation_mask: np.ndarray,\n    fit_params: dict,\n    split_idx: int | None = None,\n) -&gt; dict:\n    \"\"\"\n    Fit estimator with parameters and return validation score.\n\n    Parameters\n    ----------\n    estimator : BaseEstimator\n        Model instance to fit (works with SRF or any estimator with .reconstruct())\n    x : ndarray\n        Full data matrix\n    train_mask : ndarray of bool\n        Boolean mask where True = training entry\n    validation_mask : ndarray of bool\n        Boolean mask where True = validation entry\n    fit_params : dict\n        Parameters to set on the estimator\n    split_idx : int or None\n        Index of the CV split\n\n    Returns\n    -------\n    result : dict\n        Dictionary with score, parameters, and fitted estimator\n    \"\"\"\n    est = clone(estimator).set_params(**fit_params)\n\n    # Set SRF-specific params if estimator supports them\n    if hasattr(est, \"missing_values\"):\n        est.set_params(missing_values=np.nan)\n\n    if hasattr(est, \"bounds\"):\n        if \"bounds\" not in fit_params or fit_params[\"bounds\"] is None:\n            original_bounds = (np.nanmin(x), np.nanmax(x))\n            est.set_params(bounds=original_bounds)\n\n    # Track which entries were already NaN in the original data\n    originally_nan = np.isnan(x)\n\n    # Create training data: keep only training entries, mask everything else\n    x_train = np.full_like(x, np.nan)\n    x_train[train_mask] = x[train_mask]\n\n    # Fit model on training data only\n    est.fit(x_train)\n\n    # Get reconstruction\n    if hasattr(est, \"reconstruct\"):\n        reconstruction = est.reconstruct()\n    else:\n        raise ValueError(\n            f\"Estimator {type(est).__name__} must have a .reconstruct() method \"\n            \"for matrix completion cross-validation\"\n        )\n\n    # Evaluate only on validation entries that were originally observed\n    valid_eval_mask = validation_mask &amp; ~originally_nan\n\n    if not valid_eval_mask.any():\n        raise ValueError(\"No valid validation entries to evaluate\")\n\n    mse = np.mean((x[valid_eval_mask] - reconstruction[valid_eval_mask]) ** 2)\n\n    result = {\n        \"score\": mse,\n        \"split\": split_idx if split_idx is not None else 0,\n        \"estimator\": est,\n        \"params\": fit_params,\n    }\n\n    # Include history if available (optional)\n    if hasattr(est, \"history_\"):\n        result[\"history\"] = est.history_\n\n    return result\n</code></pre>"},{"location":"api/model/","title":"Model API","text":""},{"location":"api/model/#srf-class","title":"SRF Class","text":""},{"location":"api/model/#pysrf.SRF","title":"SRF","text":"<pre><code>SRF(\n    rank: int = 10,\n    rho: float = 3.0,\n    max_outer: int = 30,\n    max_inner: int = 20,\n    tol: float = 0.0001,\n    verbose: int = 0,\n    init: str = \"random_sqrt\",\n    random_state: int | None = None,\n    missing_values: float | None = np.nan,\n    bounds: tuple[float, float] | None = (None, None),\n)\n</code></pre> <p>             Bases: <code>TransformerMixin</code>, <code>BaseEstimator</code></p> <p>Symmetric Non-negative Matrix Factorization using SRF.</p> <p>This class implements symmetric non-negative matrix factorization (SymNMF) using the Alternating Direction Method of Multipliers (SRF). It can handle missing entries and optional bound constraints on the factorization.</p> <p>The algorithm solves: min_{w&gt;=0,v} ||M o (S - v)||^2_F + rho/2 ||v - ww^T||^2_F subject to optional bounds on v, where M is an observation mask.</p> <p>Parameters:</p> Name Type Description Default <code>rank</code> <code>int</code> <p>Number of factors (dimensionality of the latent space)</p> <code>10</code> <code>rho</code> <code>float</code> <p>SRF penalty parameter controlling constraint enforcement</p> <code>3.0</code> <code>max_outer</code> <code>int</code> <p>Maximum number of SRF outer iterations</p> <code>10</code> <code>max_inner</code> <code>int</code> <p>Maximum iterations for w-subproblem per outer iteration</p> <code>30</code> <code>tol</code> <code>float</code> <p>Convergence tolerance for constraint violation</p> <code>1e-4</code> <code>verbose</code> <code>int</code> <p>Whether to print optimization progress</p> <code>0</code> <code>init</code> <code>str</code> <p>Method for factor initialization ('random', 'random_sqrt', 'nndsvd', 'nndsvdar', 'eigenspectrum')</p> <code>'random_sqrt'</code> <code>random_state</code> <code>int or None</code> <p>Random seed for reproducible initialization</p> <code>None</code> <code>missing_values</code> <code>float or None</code> <p>Values to be treated as missing to mask the matrix</p> <code>np.nan</code> <code>bounds</code> <code>tuple of (float, float) or None</code> <p>Tuple of (lower, upper) bounds for the auxiliary variable v. If None, the bounds are inferred from the data. In practice, one can also pass the expected bounds of the matrix (e.g. (0, 1) for cosine similarity)</p> <code>(None, None)</code> <p>Attributes:</p> Name Type Description <code>w_</code> <code>np.ndarray of shape (n_samples, rank)</code> <p>Learned factor matrix w</p> <code>components_</code> <code>np.ndarray of shape (n_samples, rank)</code> <p>Alias for w_ (sklearn compatibility)</p> <code>n_iter_</code> <code>int</code> <p>Number of SRF iterations performed</p> <code>history_</code> <code>dict</code> <p>Dictionary containing optimization metrics per iteration</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Basic usage with complete data\n&gt;&gt;&gt; from pysrf import SRF\n&gt;&gt;&gt; model = SRF(rank=10, random_state=42)\n&gt;&gt;&gt; w = model.fit_transform(similarity_matrix)\n&gt;&gt;&gt; reconstruction = w @ w.T\n</code></pre> <pre><code>&gt;&gt;&gt; # Usage with missing data (NaN values)\n&gt;&gt;&gt; similarity_matrix[mask] = np.nan\n&gt;&gt;&gt; model = SRF(rank=10, missing_values=np.nan)\n&gt;&gt;&gt; w = model.fit_transform(similarity_matrix)\n</code></pre> References <p>.. [1] Shi et al. (2016). \"Inexact Block Coordinate Descent Methods For        Symmetric Nonnegative Matrix Factorization\"</p> Source code in <code>pysrf/model.py</code> <pre><code>def __init__(\n    self,\n    rank: int = 10,\n    rho: float = 3.0,\n    max_outer: int = 30,\n    max_inner: int = 20,\n    tol: float = 1e-4,\n    verbose: int = 0,\n    init: str = \"random_sqrt\",\n    random_state: int | None = None,\n    missing_values: float | None = np.nan,\n    bounds: tuple[float, float] | None = (None, None),\n) -&gt; None:\n    self.rank = rank\n    self.rho = rho\n    self.max_outer = max_outer\n    self.max_inner = max_inner\n    self.tol = tol\n    self.verbose = verbose\n    self.init = init\n    self.random_state = random_state\n    self.missing_values = missing_values\n    self.bounds = bounds\n</code></pre>"},{"location":"api/model/#pysrf.SRF.fit","title":"fit","text":"<pre><code>fit(x: np.ndarray, y: np.ndarray | None = None) -&gt; SRF\n</code></pre> <p>Fit the symmetric NMF model to the data.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array-like of shape (n_samples, n_samples)</code> <p>Symmetric similarity matrix. Missing values are allowed and should be marked according to the missing_values parameter.</p> required <code>y</code> <code>Ignored</code> <p>Not used, present here for API consistency by convention.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>self</code> <code>object</code> <p>Fitted estimator.</p> Source code in <code>pysrf/model.py</code> <pre><code>def fit(self, x: np.ndarray, y: np.ndarray | None = None) -&gt; SRF:\n    \"\"\"\n    Fit the symmetric NMF model to the data.\n\n    Parameters\n    ----------\n    x : array-like of shape (n_samples, n_samples)\n        Symmetric similarity matrix. Missing values are allowed and should\n        be marked according to the missing_values parameter.\n    y : Ignored\n        Not used, present here for API consistency by convention.\n\n    Returns\n    -------\n    self : object\n        Fitted estimator.\n    \"\"\"\n    self._validate_params()\n    _validate_bounds(self.bounds)\n\n    x = validate_data(\n        self,\n        x,\n        reset=True,\n        ensure_all_finite=(\n            \"allow-nan\" if _is_nan_marker(self.missing_values) else True\n        ),\n        ensure_2d=True,\n        dtype=np.float64,\n        copy=True,\n    )\n\n    self._missing_mask = _get_missing_mask(x, self.missing_values)\n    if np.all(self._missing_mask):\n        raise ValueError(\n            \"No observed entries found in the data. All values are missing.\"\n        )\n\n    check_symmetric(self._missing_mask, raise_exception=True)\n    self._observation_mask = ~self._missing_mask\n    x[self._missing_mask] = 0.0\n    x = check_symmetric(x, raise_exception=True, tol=1e-10)\n\n    if np.all(self._observation_mask):\n        return self._fit_complete_data(x)\n    else:\n        return self._fit_missing_data(x)\n</code></pre>"},{"location":"api/model/#pysrf.SRF.fit_transform","title":"fit_transform","text":"<pre><code>fit_transform(\n    x: np.ndarray, y: np.ndarray | None = None\n) -&gt; np.ndarray\n</code></pre> <p>Fit the model and return the learned factors.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array-like of shape (n_samples, n_samples)</code> <p>Symmetric similarity matrix</p> required <code>y</code> <code>Ignored</code> <p>Not used, present here for API consistency by convention.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>w</code> <code>array-like of shape (n_samples, rank)</code> <p>Learned factor matrix</p> Source code in <code>pysrf/model.py</code> <pre><code>def fit_transform(self, x: np.ndarray, y: np.ndarray | None = None) -&gt; np.ndarray:\n    \"\"\"\n    Fit the model and return the learned factors.\n\n    Parameters\n    ----------\n    x : array-like of shape (n_samples, n_samples)\n        Symmetric similarity matrix\n    y : Ignored\n        Not used, present here for API consistency by convention.\n\n    Returns\n    -------\n    w : array-like of shape (n_samples, rank)\n        Learned factor matrix\n    \"\"\"\n    return self.fit(x, y).transform(x)\n</code></pre>"},{"location":"api/model/#pysrf.SRF.reconstruct","title":"reconstruct","text":"<pre><code>reconstruct(w: np.ndarray | None = None) -&gt; np.ndarray\n</code></pre> <p>Reconstruct the similarity matrix from factors.</p> <p>Parameters:</p> Name Type Description Default <code>w</code> <code>array-like of shape (n_samples, rank) or None</code> <p>Factor matrix to use for reconstruction. If None, uses the fitted factors.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>s_hat</code> <code>array-like of shape (n_samples, n_samples)</code> <p>Reconstructed similarity matrix</p> Source code in <code>pysrf/model.py</code> <pre><code>def reconstruct(self, w: np.ndarray | None = None) -&gt; np.ndarray:\n    \"\"\"\n    Reconstruct the similarity matrix from factors.\n\n    Parameters\n    ----------\n    w : array-like of shape (n_samples, rank) or None\n        Factor matrix to use for reconstruction.\n        If None, uses the fitted factors.\n\n    Returns\n    -------\n    s_hat : array-like of shape (n_samples, n_samples)\n        Reconstructed similarity matrix\n    \"\"\"\n    if w is None:\n        check_is_fitted(self)\n        w = self.w_\n\n    return w @ w.T\n</code></pre>"},{"location":"api/model/#pysrf.SRF.score","title":"score","text":"<pre><code>score(x: np.ndarray, y: np.ndarray | None = None) -&gt; float\n</code></pre> <p>Score the model using reconstruction error on observed entries only.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array-like of shape (n_samples, n_samples)</code> <p>Symmetric similarity matrix. Missing values are allowed and should be marked according to the missing_values parameter.</p> required <code>y</code> <code>Ignored</code> <p>Not used, present here for API consistency by convention.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>mse</code> <code>float</code> <p>Mean squared error of the reconstruction on observed entries.</p> Source code in <code>pysrf/model.py</code> <pre><code>def score(self, x: np.ndarray, y: np.ndarray | None = None) -&gt; float:\n    \"\"\"\n    Score the model using reconstruction error on observed entries only.\n\n    Parameters\n    ----------\n    x : array-like of shape (n_samples, n_samples)\n        Symmetric similarity matrix. Missing values are allowed and should\n        be marked according to the missing_values parameter.\n    y : Ignored\n        Not used, present here for API consistency by convention.\n\n    Returns\n    -------\n    mse : float\n        Mean squared error of the reconstruction on observed entries.\n    \"\"\"\n    check_is_fitted(self)\n\n    x = validate_data(\n        self,\n        x,\n        reset=False,\n        ensure_2d=True,\n        dtype=np.float64,\n        ensure_all_finite=\"allow-nan\" if self.missing_values is np.nan else True,\n    )\n    observation_mask = ~_get_missing_mask(x, self.missing_values)\n    reconstruction = self.reconstruct()\n    mse = np.mean((x[observation_mask] - reconstruction[observation_mask]) ** 2)\n    return -mse\n</code></pre>"},{"location":"api/model/#pysrf.SRF.transform","title":"transform","text":"<pre><code>transform(x: np.ndarray) -&gt; np.ndarray\n</code></pre> <p>Project data onto the learned factor space.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array-like of shape (n_samples, n_samples)</code> <p>Symmetric matrix to transform</p> required <p>Returns:</p> Name Type Description <code>w</code> <code>array-like of shape (n_samples, rank)</code> <p>Transformed data</p> Source code in <code>pysrf/model.py</code> <pre><code>def transform(self, x: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Project data onto the learned factor space.\n\n    Parameters\n    ----------\n    x : array-like of shape (n_samples, n_samples)\n        Symmetric matrix to transform\n\n    Returns\n    -------\n    w : array-like of shape (n_samples, rank)\n        Transformed data\n    \"\"\"\n    check_is_fitted(self)\n    return self.w_\n</code></pre>"}]}