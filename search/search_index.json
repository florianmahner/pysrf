{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"pysrf","text":"<p>Symmetric Representation Factorization (SRF) - Fast matrix completion and rank estimation using ADMM optimization.</p> <p> </p>"},{"location":"#overview","title":"Overview","text":"<p><code>pysrf</code> implements symmetric non-negative matrix factorization using the Alternating Direction Method of Multipliers (ADMM). It's designed for:</p> <ul> <li>Matrix completion with missing entries</li> <li>Rank estimation via Random Matrix Theory</li> <li>Cross-validation for hyperparameter tuning</li> <li>High performance through Cython optimization (10-50x speedup)</li> </ul>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>\u2705 ADMM optimization with missing data support</li> <li>\u2705 Cython-optimized inner loop for speed</li> <li>\u2705 Automatic sampling bound estimation for cross-validation</li> <li>\u2705 Scikit-learn compatible API</li> <li>\u2705 Full type hints (Python 3.10+)</li> </ul>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>import numpy as np\nfrom pysrf import SRF\n\n# Your similarity matrix\ns = np.random.rand(100, 100)\ns = (s + s.T) / 2  # make symmetric\n\n# Fit model\nmodel = SRF(rank=10, max_outer=20, random_state=42)\nw = model.fit_transform(s)\n\n# Reconstruct\ns_reconstructed = w @ w.T\n</code></pre>"},{"location":"#installation","title":"Installation","text":"<p>See the Installation Guide for detailed instructions.</p>"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li>Quick Start Guide - Learn the basics</li> <li>API Reference - Detailed documentation</li> <li>Development Guide - Contributing guidelines</li> </ul>"},{"location":"development/","title":"Development Guide","text":""},{"location":"development/#setup-development-environment","title":"Setup Development Environment","text":""},{"location":"development/#using-the-setup-script","title":"Using the Setup Script","text":"<p>The easiest way to set up the development environment:</p> <pre><code>chmod +x setup.sh\n./setup.sh\n</code></pre> <p>This script will: 1. Install <code>pyenv</code> (if not present) 2. Install Python 3.12.4 3. Install Poetry 4. Install all dependencies 5. Compile Cython extensions 6. Run tests</p>"},{"location":"development/#manual-setup","title":"Manual Setup","text":"<pre><code># Install poetry\ncurl -sSL https://install.python-poetry.org | python3 -\n\n# Install dependencies\npoetry install\n\n# Compile Cython extensions\npoetry run pysrf-compile\n\n# Run tests\npoetry run pytest\n</code></pre>"},{"location":"development/#makefile-commands","title":"Makefile Commands","text":"<p>The project includes a Makefile for common development tasks:</p> <pre><code>make help          # Show all available commands\nmake dev           # Install with dev dependencies + compile Cython\nmake compile       # Compile Cython extensions\nmake test          # Run test suite\nmake test-cov      # Run tests with coverage report\nmake lint          # Run linters (ruff + black)\nmake format        # Format code with black\nmake clean         # Remove build artifacts\nmake build         # Build distribution package\nmake docs          # Build documentation\nmake docs-serve    # Serve documentation locally\n</code></pre>"},{"location":"development/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\nmake test\n\n# Run with coverage\nmake test-cov\n\n# Run specific test file\npoetry run pytest tests/test_model.py -v\n\n# Run specific test\npoetry run pytest tests/test_model.py::test_srf_fit_complete_data -v\n</code></pre>"},{"location":"development/#code-quality","title":"Code Quality","text":""},{"location":"development/#linting","title":"Linting","text":"<pre><code># Check code quality\nmake lint\n\n# Auto-format code\nmake format\n</code></pre>"},{"location":"development/#type-checking","title":"Type Checking","text":"<p>The codebase uses Python 3.10+ type hints:</p> <pre><code>from __future__ import annotations\n\ndef my_function(x: np.ndarray, rank: int = 10) -&gt; tuple[np.ndarray, float]:\n    ...\n</code></pre>"},{"location":"development/#cython-extensions","title":"Cython Extensions","text":"<p>The performance-critical inner loop is implemented in Cython (<code>_bsum.pyx</code>):</p> <pre><code># Compile Cython extensions\nmake compile\n\n# Or directly\npoetry run pysrf-compile\n</code></pre>"},{"location":"development/#testing-cython-vs-python","title":"Testing Cython vs Python","text":"<pre><code>from pysrf.model import _get_update_w_function\n\nupdate_w = _get_update_w_function()\nprint(f\"Using: {update_w.__module__}\")\n# Cython: _bsum\n# Python fallback: pysrf.model\n</code></pre>"},{"location":"development/#documentation","title":"Documentation","text":""},{"location":"development/#building-docs","title":"Building Docs","text":"<pre><code># Build documentation\nmake docs\n\n# Serve locally at http://127.0.0.1:8000\nmake docs-serve\n</code></pre>"},{"location":"development/#writing-docstrings","title":"Writing Docstrings","text":"<p>Use NumPy-style docstrings:</p> <pre><code>def my_function(x: np.ndarray, param: int = 10) -&gt; float:\n    \"\"\"\n    Brief description.\n\n    Longer description explaining the function's purpose and behavior.\n\n    Parameters\n    ----------\n    x : ndarray\n        Description of x\n    param : int, default=10\n        Description of param\n\n    Returns\n    -------\n    result : float\n        Description of return value\n\n    Examples\n    --------\n    &gt;&gt;&gt; result = my_function(np.array([1, 2, 3]))\n    &gt;&gt;&gt; print(result)\n    0.123\n    \"\"\"\n    ...\n</code></pre>"},{"location":"development/#contributing","title":"Contributing","text":""},{"location":"development/#workflow","title":"Workflow","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch: <code>git checkout -b feature-name</code></li> <li>Make your changes</li> <li>Run tests: <code>make test</code></li> <li>Format code: <code>make format</code></li> <li>Commit: <code>git commit -m \"Add feature\"</code></li> <li>Push: <code>git push origin feature-name</code></li> <li>Open a Pull Request</li> </ol>"},{"location":"development/#guidelines","title":"Guidelines","text":"<ul> <li>Write tests for new features</li> <li>Maintain type hints</li> <li>Update documentation</li> <li>Keep changes focused</li> <li>Follow existing code style</li> </ul>"},{"location":"development/#publishing","title":"Publishing","text":""},{"location":"development/#pypi-release","title":"PyPI Release","text":"<pre><code># Update version in pyproject.toml\npoetry version patch  # or minor, major\n\n# Build package\nmake build\n\n# Publish to PyPI\npoetry publish\n</code></pre>"},{"location":"development/#development-release","title":"Development Release","text":"<pre><code># Build with dev version\npoetry version prerelease\n\n# Publish to TestPyPI\npoetry publish -r testpypi\n</code></pre>"},{"location":"development/#project-structure","title":"Project Structure","text":"<pre><code>pysrf/\n\u251c\u2500\u2500 pysrf/              # Main package\n\u2502   \u251c\u2500\u2500 __init__.py    # Public API\n\u2502   \u251c\u2500\u2500 model.py       # SRF class\n\u2502   \u251c\u2500\u2500 cross_validation.py\n\u2502   \u251c\u2500\u2500 bounds.py      # Sampling bound estimation\n\u2502   \u251c\u2500\u2500 utils.py       # Helper functions\n\u2502   \u2514\u2500\u2500 _bsum.pyx      # Cython extension\n\u251c\u2500\u2500 tests/             # Test suite\n\u251c\u2500\u2500 docs/              # Documentation\n\u251c\u2500\u2500 build.py           # Cython build script\n\u251c\u2500\u2500 Makefile           # Development commands\n\u251c\u2500\u2500 pyproject.toml     # Poetry config\n\u2514\u2500\u2500 README.md          # Project overview\n</code></pre>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#from-pypi","title":"From PyPI","text":"<pre><code>pip install pysrf\n</code></pre> <p>Cython Compilation</p> <p>For optimal performance (10-50x speedup), ensure Cython extensions are compiled during installation. You may need development tools installed.</p>"},{"location":"installation/#from-source","title":"From Source","text":""},{"location":"installation/#using-poetry-recommended","title":"Using Poetry (Recommended)","text":"<pre><code>git clone https://github.com/fmahner/pysrf.git\ncd pysrf\npoetry install\npoetry run pysrf-compile  # Compile Cython extensions\n</code></pre>"},{"location":"installation/#using-pip","title":"Using pip","text":"<pre><code>git clone https://github.com/fmahner/pysrf.git\ncd pysrf\npip install -e .\n</code></pre>"},{"location":"installation/#as-a-git-subtree","title":"As a Git Subtree","text":"<p>For development, you can add <code>pysrf</code> as a subtree in your project:</p> <pre><code># Add as subtree\ngit subtree add --prefix=pysrf https://github.com/fmahner/pysrf.git main --squash\n\n# Update later\ngit subtree pull --prefix=pysrf https://github.com/fmahner/pysrf.git main --squash\n</code></pre>"},{"location":"installation/#verify-installation","title":"Verify Installation","text":"<pre><code>import pysrf\nprint(pysrf.__version__)\n\n# Check Cython compilation\nfrom pysrf.model import _get_update_w_function\nupdate_w = _get_update_w_function()\nprint(f\"Using: {update_w.__module__}\")  # Should show _bsum if compiled\n</code></pre>"},{"location":"installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.10+</li> <li>NumPy \u2265 1.23</li> <li>scikit-learn \u2265 1.3</li> <li>SciPy \u2265 1.10</li> <li>pandas \u2265 2.0</li> <li>joblib \u2265 1.0</li> </ul>"},{"location":"installation/#optional-development","title":"Optional (Development)","text":"<ul> <li>Cython \u2265 3.0 (for compilation)</li> <li>pytest \u2265 7.0 (for testing)</li> <li>mkdocs-material (for documentation)</li> </ul>"},{"location":"quickstart/","title":"Quick Start","text":""},{"location":"quickstart/#basic-usage","title":"Basic Usage","text":""},{"location":"quickstart/#matrix-factorization","title":"Matrix Factorization","text":"<pre><code>import numpy as np\nfrom pysrf import SRF\n\n# Generate or load your similarity matrix\ns = np.random.rand(100, 100)\ns = (s + s.T) / 2  # ensure symmetry\n\n# Fit the model\nmodel = SRF(rank=10, max_outer=20, random_state=42)\nw = model.fit_transform(s)\n\n# Reconstruct the matrix\ns_reconstructed = model.reconstruct()\n# or equivalently: s_reconstructed = w @ w.T\n\n# Evaluate fit\nscore = model.score(s)\nprint(f\"Reconstruction error: {score:.4f}\")\n</code></pre>"},{"location":"quickstart/#handling-missing-data","title":"Handling Missing Data","text":"<pre><code>import numpy as np\nfrom pysrf import SRF\n\n# Matrix with missing values (NaN)\ns = np.random.rand(100, 100)\ns = (s + s.T) / 2\ns[np.random.rand(100, 100) &lt; 0.3] = np.nan  # 30% missing\n\n# Model handles missing data automatically\nmodel = SRF(rank=10, missing_values=np.nan, random_state=42)\nw = model.fit_transform(s)\ns_completed = model.reconstruct()\n</code></pre>"},{"location":"quickstart/#cross-validation","title":"Cross-Validation","text":""},{"location":"quickstart/#manual-sampling-fraction","title":"Manual Sampling Fraction","text":"<pre><code>from pysrf import cross_val_score\n\n# Define parameter grid\nparam_grid = {\n    'rank': [5, 10, 15, 20],\n    'rho': [2.0, 3.0, 4.0]\n}\n\n# Run cross-validation\nresult = cross_val_score(\n    s,\n    param_grid=param_grid,\n    sampling_fraction=0.8,  # 80/20 train/test split\n    n_repeats=5,\n    n_jobs=-1,\n    random_state=42\n)\n\nprint(f\"Best parameters: {result.best_params_}\")\nprint(f\"Best score: {result.best_score_:.4f}\")\n</code></pre>"},{"location":"quickstart/#automatic-sampling-fraction-estimation","title":"Automatic Sampling Fraction Estimation","text":"<p>The optimal sampling fraction can be automatically estimated using Random Matrix Theory:</p> <pre><code>from pysrf import cross_val_score\n\n# Automatically estimate optimal sampling fraction\nresult = cross_val_score(\n    s,\n    param_grid={'rank': [5, 10, 15, 20]},\n    estimate_sampling_fraction=True,  # \u2728 New feature!\n    n_repeats=5,\n    n_jobs=-1,\n    random_state=42,\n    verbose=1  # Shows estimated bounds\n)\n\nprint(f\"Best rank: {result.best_params_['rank']}\")\n</code></pre>"},{"location":"quickstart/#sampling-bound-estimation","title":"Sampling Bound Estimation","text":"<p>Estimate the sampling rate bounds required for reliable matrix completion:</p> <pre><code>from pysrf import estimate_sampling_bounds_fast\n\n# Estimate bounds\npmin, pmax, s_denoised = estimate_sampling_bounds_fast(\n    s,\n    n_jobs=-1,\n    random_state=42\n)\n\nprint(f\"Minimum sampling rate: {pmin:.4f}\")\nprint(f\"Maximum sampling rate: {pmax:.4f}\")\n\n# Use mid-point for cross-validation\nsampling_rate = 0.5 * (pmin + pmax)\n</code></pre>"},{"location":"quickstart/#value-bounds","title":"Value Bounds","text":"<p>Constrain reconstructed values to known ranges:</p> <pre><code>from pysrf import SRF\n\n# For cosine similarity (range: [0, 1])\nmodel = SRF(rank=10, bounds=(0, 1), random_state=42)\nw = model.fit_transform(s)\ns_reconstructed = model.reconstruct()\n\n# Verify bounds\nassert s_reconstructed.min() &gt;= 0\nassert s_reconstructed.max() &lt;= 1\n</code></pre>"},{"location":"quickstart/#complete-example","title":"Complete Example","text":"<pre><code>import numpy as np\nfrom pysrf import SRF, cross_val_score, estimate_sampling_bounds_fast\n\n# 1. Generate data\nnp.random.seed(42)\nn, true_rank = 100, 8\nw_true = np.random.rand(n, true_rank)\ns = w_true @ w_true.T\n\n# 2. Add noise and missing data\ns += 0.1 * np.random.randn(n, n)\ns = (s + s.T) / 2\nmask = np.random.rand(n, n) &lt; 0.2\ns[mask] = np.nan\n\n# 3. Estimate sampling bounds\npmin, pmax, _ = estimate_sampling_bounds_fast(s, n_jobs=-1)\nprint(f\"Sampling bounds: [{pmin:.3f}, {pmax:.3f}]\")\n\n# 4. Cross-validate to find best rank\nresult = cross_val_score(\n    s,\n    param_grid={'rank': range(5, 21)},\n    estimate_sampling_fraction=True,\n    n_repeats=3,\n    n_jobs=-1,\n    random_state=42\n)\nbest_rank = result.best_params_['rank']\nprint(f\"Best rank: {best_rank} (true rank: {true_rank})\")\n\n# 5. Fit final model\nmodel = SRF(rank=best_rank, max_outer=20, random_state=42)\nw = model.fit_transform(s)\ns_completed = model.reconstruct()\n\n# 6. Evaluate\nscore = model.score(s)\nprint(f\"Reconstruction error: {score:.4f}\")\n</code></pre>"},{"location":"quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Check the API Reference for detailed parameter descriptions</li> <li>See Development for contributing guidelines</li> </ul>"},{"location":"api/bounds/","title":"Sampling Bounds API","text":""},{"location":"api/bounds/#main-functions","title":"Main Functions","text":""},{"location":"api/bounds/#pysrf.estimate_sampling_bounds_fast","title":"estimate_sampling_bounds_fast","text":"<pre><code>estimate_sampling_bounds_fast(\n    S: np.ndarray,\n    gamma: float = 1.05,\n    eta: float = 0.05,\n    rho: float = 0.95,\n    method: str = \"dyson\",\n    omega: float = 0.8,\n    eta_pmax: float = 0.001,\n    jump_frac: float = 0.1,\n    tol: float = 0.0001,\n    gap: float = 0.05,\n    verbose: bool = False,\n    random_state: int = 31213,\n    n_jobs: int = -1,\n) -&gt; tuple[float, float, np.ndarray]\n</code></pre> Source code in <code>pysrf/bounds.py</code> <pre><code>def estimate_sampling_bounds_fast(\n    S: np.ndarray,\n    gamma: float = 1.05,\n    eta: float = 0.05,\n    rho: float = 0.95,\n    method: str = \"dyson\",\n    omega: float = 0.8,\n    eta_pmax: float = 1e-3,\n    jump_frac: float = 0.1,\n    tol: float = 1e-4,\n    gap: float = 0.05,\n    verbose: bool = False,\n    random_state: int = 31213,\n    n_jobs: int = -1,\n) -&gt; tuple[float, float, np.ndarray]:\n    pmin, _, _, _, _ = pmin_bound(\n        S, gamma=gamma, eta=eta, rho=rho, random_state=random_state, verbose=verbose\n    )\n\n    eff_dim = np.ceil((np.linalg.norm(S, \"fro\") / np.linalg.norm(S, 2)) ** 2).astype(\n        int\n    )\n\n    pmax = p_upper_only_k(\n        S,\n        k=eff_dim,\n        method=method,\n        tol=tol,\n        omega=omega,\n        eta=eta_pmax,\n        jump_frac=jump_frac,\n        verbose=verbose,\n        seed=random_state,\n    )\n\n    S_noise = S\n\n    if pmin &gt; pmax - gap:\n        epsilon = np.linalg.norm(S, 2) / np.sqrt(S.shape[0])\n        t_range = np.linspace(0.0, epsilon, 10)\n\n        A = np.random.rand(S.shape[0], S.shape[1])\n        AtA = A + A.T\n\n        def _eval_t(t):\n            S_t = S + t * AtA\n            pmin_t, _, _, _, _ = pmin_bound(\n                S_t,\n                gamma=gamma,\n                eta=eta,\n                rho=rho,\n                random_state=random_state,\n                verbose=verbose,\n            )\n            eff_dim_t = np.ceil(\n                (np.linalg.norm(S_t, \"fro\") / np.linalg.norm(S_t, 2)) ** 2\n            ).astype(int)\n            pmax_t = p_upper_only_k(\n                S_t,\n                k=eff_dim_t,\n                method=method,\n                tol=tol,\n                omega=omega,\n                eta=eta_pmax,\n                jump_frac=jump_frac,\n                verbose=verbose,\n                seed=random_state,\n            )\n            return float(pmin_t), float(pmax_t)\n\n        results = Parallel(n_jobs=n_jobs)(delayed(_eval_t)(float(t)) for t in t_range)\n\n        idx = None\n        for i, (pm, px) in enumerate(results):\n            if pm &lt; px - gap:\n                idx = i\n                break\n\n        if idx is not None:\n            t_threshold = float(t_range[idx])\n            pmin, pmax = results[idx]\n        else:\n            t_threshold = 0.0\n            pmin, pmax = results[-1]\n\n        S_noise = S + t_threshold * AtA\n\n    return pmin, pmax, S_noise\n</code></pre>"},{"location":"api/bounds/#pysrf.estimate_sampling_bounds","title":"estimate_sampling_bounds","text":"<pre><code>estimate_sampling_bounds(\n    S: np.ndarray,\n    gamma: float = 1.05,\n    eta: float = 0.05,\n    rho: float = 0.95,\n    method: str = \"dyson\",\n    omega: float = 0.8,\n    eta_pmax: float = 0.001,\n    jump_frac: float = 0.1,\n    tol: float = 0.0001,\n    gap: float = 0.05,\n    verbose: bool = False,\n    random_state: int = 31213,\n) -&gt; tuple[float, float, np.ndarray]\n</code></pre> Source code in <code>pysrf/bounds.py</code> <pre><code>def estimate_sampling_bounds(\n    S: np.ndarray,\n    gamma: float = 1.05,\n    eta: float = 0.05,\n    rho: float = 0.95,\n    method: str = \"dyson\",\n    omega: float = 0.8,\n    eta_pmax: float = 1e-3,\n    jump_frac: float = 0.1,\n    tol: float = 1e-4,\n    gap: float = 0.05,\n    verbose: bool = False,\n    random_state: int = 31213,\n) -&gt; tuple[float, float, np.ndarray]:\n    pmin, _, _, _, _ = pmin_bound(\n        S, gamma=gamma, eta=eta, rho=rho, random_state=random_state, verbose=verbose\n    )\n\n    eff_dim = np.ceil((np.linalg.norm(S, \"fro\") / np.linalg.norm(S, 2)) ** 2).astype(\n        int\n    )\n\n    pmax = p_upper_only_k(\n        S,\n        k=eff_dim,\n        method=method,\n        tol=tol,\n        omega=omega,\n        eta=eta_pmax,\n        jump_frac=jump_frac,\n        verbose=verbose,\n        seed=random_state,\n    )\n\n    S_noise = S\n\n    if pmin &gt; pmax - gap:\n        if verbose:\n            print(\"Noise regime triggered\")\n            print(f\"pmin = {pmin}, pmax = {pmax}\")\n\n        epsilon = np.linalg.norm(S, 2) / np.sqrt(S.shape[0])\n\n        t_range = np.linspace(0.0, epsilon, 10)\n        eff_dim_list = []\n        pmin_list = []\n        pmax_list = []\n\n        A = np.random.rand(S.shape[0], S.shape[1])\n\n        t_threshold = 0\n\n        t_iter = iter(t_range)\n        t = next(t_iter)\n\n        while True:\n            S_noise = S + t * (A + A.T)\n\n            pmin, _, _, _, _ = pmin_bound(\n                S_noise,\n                gamma=gamma,\n                eta=eta,\n                rho=rho,\n                random_state=random_state,\n                verbose=verbose,\n            )\n\n            eff_dim = np.ceil(\n                (np.linalg.norm(S_noise, \"fro\") / np.linalg.norm(S_noise, 2)) ** 2\n            ).astype(int)\n            pmax = p_upper_only_k(\n                S_noise,\n                k=eff_dim,\n                method=method,\n                tol=tol,\n                omega=omega,\n                eta=eta_pmax,\n                jump_frac=jump_frac,\n                verbose=verbose,\n                seed=random_state,\n            )\n            if verbose:\n                print(t, pmin, eff_dim, pmax)\n\n            eff_dim_list.append(eff_dim)\n            pmin_list.append(pmin)\n            pmax_list.append(pmax)\n\n            if pmin &lt; pmax - gap:\n                t_threshold = t\n                break\n\n            try:\n                t = next(t_iter)\n            except StopIteration:\n                break\n\n        S_noise = S + t_threshold * (A + A.T)\n\n    return pmin, pmax, S_noise\n</code></pre>"},{"location":"api/bounds/#lower-bound-estimation","title":"Lower Bound Estimation","text":""},{"location":"api/bounds/#pysrf.pmin_bound","title":"pmin_bound","text":"<pre><code>pmin_bound(\n    S: np.ndarray,\n    gamma: float = 1.05,\n    eta: float = 0.05,\n    rho: float = 0.95,\n    n_realizations: int = 500,\n    random_state: int | None = None,\n    verbose: bool = False,\n    monte_carlo: bool = False,\n) -&gt; tuple[float, float, float, float, np.ndarray]\n</code></pre> Source code in <code>pysrf/bounds.py</code> <pre><code>def pmin_bound(\n    S: np.ndarray,\n    gamma: float = 1.05,\n    eta: float = 0.05,\n    rho: float = 0.95,\n    n_realizations: int = 500,\n    random_state: int | None = None,\n    verbose: bool = False,\n    monte_carlo: bool = False,\n) -&gt; tuple[float, float, float, float, np.ndarray]:\n    np.random.seed(random_state)\n    n = S.shape[0]\n    _is_symmetric = np.allclose(S, S.T)\n\n    L_max = np.max((S**2).sum(axis=1) - np.diag(S) ** 2)\n\n    _row_sq = (S**2).sum(axis=1) - np.diag(S) ** 2\n    empirical_L_max = np.quantile(_row_sq, rho)\n\n    S_norm = np.linalg.norm(S, 2)\n\n    L_infty = 2 * np.max(np.abs(S))\n    empirical_L_infty = 2 * np.quantile(np.abs(S), rho)\n\n    effective_dimension = (np.linalg.norm(S, \"fro\") / S_norm) ** 2\n    if verbose:\n        print(\"effective dimension : \", effective_dimension)\n\n    MC_expected_MS_norms = np.zeros(n_realizations)\n    if monte_carlo:\n        for i in range(n_realizations):\n            _p = np.random.rand()\n            _mask = np.random.binomial(1, _p, size=S.shape)\n            if _is_symmetric:\n                _mask = np.triu(_mask, 1)\n                _mask += _mask.T\n            MC_expected_MS_norms[i] = np.linalg.norm(_mask * S, 2)\n\n    N_bernstein = (gamma * L_infty * S_norm) / (3 * L_max) + 1\n    N_empirical = (gamma * empirical_L_infty * S_norm) / (3 * empirical_L_max) + 1\n    N_empirical_alternative = (gamma * L_infty * S_norm) / (3 * empirical_L_max) + 1\n    N_theory_upperbound = (gamma * S_norm) / 3 + 1\n\n    D_bernstein = ((gamma * S_norm) ** 2 / (2 * L_max) + 1) / np.log(2 * n / eta)\n    D_empirical = ((gamma * S_norm) ** 2 / (2 * empirical_L_max) + 1) / np.log(\n        2 * effective_dimension / eta\n    )\n    D_theory_lowerbound = ((gamma**2 * S_norm) / (2 * empirical_L_max) + 1) / np.log(\n        2 * n / eta\n    )\n\n    if verbose:\n        print(N_bernstein, D_bernstein)\n        print(N_empirical, D_empirical)\n        print(N_empirical_alternative, D_empirical)\n        print(N_theory_upperbound, D_theory_lowerbound)\n\n    p_min = N_bernstein / D_bernstein\n    p_min_empirical = N_empirical / D_empirical\n    p_min_empirical_alternative = N_empirical_alternative / D_empirical\n    p_min_lowerbound = N_theory_upperbound / D_theory_lowerbound\n\n    if verbose:\n        print(\"p_min\", p_min)\n        print(\"empirical_p_min\", p_min_empirical)\n        print(\"empirical_p_min_alternative\", p_min_empirical_alternative)\n        print(\"theory_p_min\", p_min_lowerbound)\n\n    return (\n        p_min_empirical,\n        p_min,\n        p_min_lowerbound,\n        p_min_empirical_alternative,\n        MC_expected_MS_norms,\n    )\n</code></pre>"},{"location":"api/bounds/#upper-bound-estimation","title":"Upper Bound Estimation","text":""},{"location":"api/bounds/#pysrf.p_upper_only_k","title":"p_upper_only_k","text":"<pre><code>p_upper_only_k(\n    S: np.ndarray,\n    k: int = 1,\n    method: str = \"dyson\",\n    mc_trials: int = 600,\n    mc_quantile: float = 0.9,\n    tol: float = 0.0001,\n    verbose: bool = False,\n    seed: int | None = None,\n    omega: float = 0.8,\n    eta: float = 0.001,\n    jump_frac: float = 0.1,\n) -&gt; float\n</code></pre> Source code in <code>pysrf/bounds.py</code> <pre><code>def p_upper_only_k(\n    S: np.ndarray,\n    k: int = 1,\n    method: str = \"dyson\",\n    mc_trials: int = 600,\n    mc_quantile: float = 0.9,\n    tol: float = 1e-4,\n    verbose: bool = False,\n    seed: int | None = None,\n    omega: float = 0.8,\n    eta: float = 1e-3,\n    jump_frac: float = 0.1,\n) -&gt; float:\n    lam = np.sort(eigvalsh(S))[::-1]\n    n = len(lam)\n    if not (1 &lt;= k &lt;= n):\n        raise ValueError(\"k must be between 1 and n\")\n    lam_k = lam[k - 1]\n    lam_k1 = lam[k] if k &lt; n else None\n\n    if lam_k &lt;= 0:\n        if verbose:\n            print(\"lambda_k &lt;= 0 -&gt; no positive spike to separate.\")\n        return 0.0\n    if (lam_k1 is None) or (lam_k1 &lt;= 0):\n        if verbose:\n            print(\n                \"lambda_{k+1} &lt;= 0 -&gt; only first k can be out for all large p; return 1.0.\"\n            )\n        return 1.0\n\n    edge = (\n        (\n            lambda p: lambda_bulk_dyson_raw(\n                S, p, omega=omega, eta=eta, jump_frac=jump_frac\n            )\n        )\n        if method == \"dyson\"\n        else (\n            lambda p: monte_carlo_bulk_edge_raw(\n                S, p, n_trials=mc_trials, quantile=mc_quantile, seed=seed\n            )\n        )\n    )\n\n    def count_out(p):\n        e = edge(p)\n        return int(np.sum(p * lam &gt; e)), e\n\n    c_hi, e_hi = count_out(0.99)\n    if verbose:\n        print(\n            f\"[sanity] p=0.99: bulk={e_hi:.4g}, count_out={c_hi}, lambda1={lam[0]:.4g}, lambda2={lam[1] if n&gt;1 else np.nan:.4g}\"\n        )\n\n    if c_hi &lt; k:\n        if verbose:\n            print(f\"Even at p~1, only {c_hi} spikes out (&lt; k). Returning 1.0.\")\n        return 1.0\n\n    grid = np.linspace(0.02, 0.99, 80)\n    feas = [p for p in grid if count_out(p)[0] == k]\n    if not feas:\n\n        def g(p):\n            return p * lam_k1 - edge(p)\n\n        a, b = 1e-3, 0.99\n        ga, gb = g(a), g(b)\n\n        if ga &gt;= 0 and gb &gt;= 0:\n            if verbose:\n                print(\n                    \"(k+1) spike is out for all p; returning smallest p where count==k (none found) -&gt; 0.\"\n                )\n            return 0.0\n\n        if ga &lt; 0 and gb &lt;= 0:\n            if verbose:\n                print(\"(k+1) never emerges up to 0.99; returning 1.0.\")\n            return 1.0\n\n        lo, hi = a, b\n        for _ in range(60):\n            mid = 0.5 * (lo + hi)\n            if g(mid) &gt;= 0:\n                hi = mid\n            else:\n                lo = mid\n            if (hi - lo) &lt; tol:\n                break\n\n        p_star = max(0.0, min(1.0, lo - 2 * tol))\n\n        return p_star\n\n    p_lo = max(feas)\n\n    def cond_ge_kplus1(p):\n        return count_out(p)[0] &gt;= (k + 1)\n\n    p_hi = min(0.99, p_lo + 0.05)\n    while (p_hi &lt; 0.99) and (not cond_ge_kplus1(p_hi)):\n        p_hi = min(0.99, p_hi + 0.05)\n    if not cond_ge_kplus1(p_hi):\n        return 1.0\n    lo, hi = p_lo, p_hi\n    for _ in range(60):\n        mid = 0.5 * (lo + hi)\n        if cond_ge_kplus1(mid):\n            hi = mid\n        else:\n            lo = mid\n        if (hi - lo) &lt; tol:\n            break\n    p_star = max(0.0, min(1.0, lo))\n    if verbose:\n        c_star, e_star = count_out(p_star)\n        print(f\"p*={p_star:.4f}, bulk={e_star:.6g}, count_out(p*)={c_star}\")\n    return p_star\n</code></pre>"},{"location":"api/cross_validation/","title":"Cross-Validation API","text":""},{"location":"api/cross_validation/#main-function","title":"Main Function","text":""},{"location":"api/cross_validation/#pysrf.cross_val_score","title":"cross_val_score","text":"<pre><code>cross_val_score(\n    similarity_matrix: np.ndarray,\n    param_grid: dict[str, list] | None = None,\n    n_repeats: int = 5,\n    sampling_fraction: float = 0.8,\n    estimate_sampling_fraction: bool | dict = False,\n    random_state: int = 0,\n    verbose: int = 1,\n    n_jobs: int = -1,\n    missing_values: float | None = np.nan,\n    fit_final_estimator: bool = False,\n) -&gt; ADMMGridSearchCV\n</code></pre> <p>Cross-validate SRF parameters for matrix completion.</p> <p>Convenience function that sets up grid search cross-validation for symmetric matrix factorization with optional automatic sampling fraction estimation.</p> <p>Parameters:</p> Name Type Description Default <code>similarity_matrix</code> <code>ndarray</code> <p>Symmetric similarity matrix to cross-validate</p> required <code>param_grid</code> <code>dict or None</code> <p>Dictionary with parameter names (str) as keys and lists of values to try as values. If None, uses default {'rank': [5, 10, 15, 20]}</p> <code>None</code> <code>n_repeats</code> <code>int</code> <p>Number of times to repeat the cross-validation</p> <code>5</code> <code>sampling_fraction</code> <code>float</code> <p>Fraction of observed entries to use for training in each split (0.0 to 1.0). Ignored if estimate_sampling_fraction is True or dict</p> <code>0.8</code> <code>estimate_sampling_fraction</code> <code>bool or dict</code> <p>If True, automatically estimate optimal sampling fraction using sampling bound estimation from Random Matrix Theory. If dict, passed as kwargs to estimate_sampling_bounds_fast(). When enabled, overrides sampling_fraction</p> <code>False</code> <code>random_state</code> <code>int</code> <p>Random seed for reproducibility</p> <code>0</code> <code>verbose</code> <code>int</code> <p>Verbosity level</p> <code>1</code> <code>n_jobs</code> <code>int</code> <p>Number of jobs to run in parallel (-1 uses all processors)</p> <code>-1</code> <code>missing_values</code> <code>float or None</code> <p>Value to consider as missing</p> <code>np.nan</code> <code>fit_final_estimator</code> <code>bool</code> <p>Whether to fit the final estimator on the best parameters</p> <code>False</code> <p>Returns:</p> Name Type Description <code>grid</code> <code>ADMMGridSearchCV</code> <p>Fitted ADMMGridSearchCV object with best parameters and scores</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from pysrf import cross_val_score\n&gt;&gt;&gt; param_grid = {'rank': [5, 10, 15], 'rho': [2.0, 3.0]}\n&gt;&gt;&gt; result = cross_val_score(similarity_matrix, param_grid=param_grid)\n&gt;&gt;&gt; print(f\"Best params: {result.best_params_}\")\n&gt;&gt;&gt; print(f\"Best score: {result.best_score_}\")\n</code></pre> <pre><code>&gt;&gt;&gt; # Automatic sampling fraction estimation\n&gt;&gt;&gt; result = cross_val_score(\n...     similarity_matrix,\n...     param_grid={'rank': [5, 10, 15]},\n...     estimate_sampling_fraction=True\n... )\n</code></pre> Source code in <code>pysrf/cross_validation.py</code> <pre><code>def cross_val_score(\n    similarity_matrix: np.ndarray,\n    param_grid: dict[str, list] | None = None,\n    n_repeats: int = 5,\n    sampling_fraction: float = 0.8,\n    estimate_sampling_fraction: bool | dict = False,\n    random_state: int = 0,\n    verbose: int = 1,\n    n_jobs: int = -1,\n    missing_values: float | None = np.nan,\n    fit_final_estimator: bool = False,\n) -&gt; ADMMGridSearchCV:\n    \"\"\"\n    Cross-validate SRF parameters for matrix completion.\n\n    Convenience function that sets up grid search cross-validation for\n    symmetric matrix factorization with optional automatic sampling fraction estimation.\n\n    Parameters\n    ----------\n    similarity_matrix : ndarray\n        Symmetric similarity matrix to cross-validate\n    param_grid : dict or None, default=None\n        Dictionary with parameter names (str) as keys and lists of values to try\n        as values. If None, uses default {'rank': [5, 10, 15, 20]}\n    n_repeats : int, default=5\n        Number of times to repeat the cross-validation\n    sampling_fraction : float, default=0.8\n        Fraction of observed entries to use for training in each split (0.0 to 1.0).\n        Ignored if estimate_sampling_fraction is True or dict\n    estimate_sampling_fraction : bool or dict, default=False\n        If True, automatically estimate optimal sampling fraction using sampling\n        bound estimation from Random Matrix Theory. If dict, passed as kwargs to\n        estimate_sampling_bounds_fast(). When enabled, overrides sampling_fraction\n    random_state : int, default=0\n        Random seed for reproducibility\n    verbose : int, default=1\n        Verbosity level\n    n_jobs : int, default=-1\n        Number of jobs to run in parallel (-1 uses all processors)\n    missing_values : float or None, default=np.nan\n        Value to consider as missing\n    fit_final_estimator : bool, default=False\n        Whether to fit the final estimator on the best parameters\n\n    Returns\n    -------\n    grid : ADMMGridSearchCV\n        Fitted ADMMGridSearchCV object with best parameters and scores\n\n    Examples\n    --------\n    &gt;&gt;&gt; from pysrf import cross_val_score\n    &gt;&gt;&gt; param_grid = {'rank': [5, 10, 15], 'rho': [2.0, 3.0]}\n    &gt;&gt;&gt; result = cross_val_score(similarity_matrix, param_grid=param_grid)\n    &gt;&gt;&gt; print(f\"Best params: {result.best_params_}\")\n    &gt;&gt;&gt; print(f\"Best score: {result.best_score_}\")\n\n    &gt;&gt;&gt; # Automatic sampling fraction estimation\n    &gt;&gt;&gt; result = cross_val_score(\n    ...     similarity_matrix,\n    ...     param_grid={'rank': [5, 10, 15]},\n    ...     estimate_sampling_fraction=True\n    ... )\n    \"\"\"\n    if param_grid is None:\n        param_grid = {\"rank\": [5, 10, 15, 20]}\n\n    if estimate_sampling_fraction:\n        from .bounds import estimate_sampling_bounds_fast\n\n        kwargs = (\n            estimate_sampling_fraction\n            if isinstance(estimate_sampling_fraction, dict)\n            else {}\n        )\n        if \"random_state\" not in kwargs:\n            kwargs[\"random_state\"] = random_state\n        if \"n_jobs\" not in kwargs:\n            kwargs[\"n_jobs\"] = n_jobs\n        if \"verbose\" not in kwargs:\n            kwargs[\"verbose\"] = bool(verbose)\n\n        pmin, pmax, _ = estimate_sampling_bounds_fast(similarity_matrix, **kwargs)\n        sampling_fraction = 0.5 * (pmin + pmax)\n\n        if verbose:\n            print(f\"Estimated sampling bounds: pmin={pmin:.4f}, pmax={pmax:.4f}\")\n            print(f\"Using sampling_fraction={sampling_fraction:.4f}\")\n\n    cv = EntryMaskSplit(\n        n_repeats=n_repeats,\n        sampling_fraction=sampling_fraction,\n        random_state=random_state,\n        missing_values=missing_values,\n    )\n    grid = ADMMGridSearchCV(\n        estimator=SRF(random_state=random_state),\n        param_grid=param_grid,\n        cv=cv,\n        n_jobs=n_jobs,\n        verbose=verbose,\n        fit_final_estimator=fit_final_estimator,\n    )\n    return grid.fit(similarity_matrix)\n</code></pre>"},{"location":"api/cross_validation/#cross-validator","title":"Cross-Validator","text":""},{"location":"api/cross_validation/#pysrf.EntryMaskSplit","title":"EntryMaskSplit","text":"<pre><code>EntryMaskSplit(\n    n_repeats: int = 5,\n    sampling_fraction: float = 0.8,\n    random_state: int | None = None,\n    missing_values: float | None = np.nan,\n)\n</code></pre> <p>             Bases: <code>BaseCrossValidator</code></p> <p>Cross-validator for symmetric matrices using entry-wise splits.</p> <p>Generates multiple random train/validation splits by masking entries in a symmetric matrix while preserving symmetry.</p> <p>Parameters:</p> Name Type Description Default <code>n_repeats</code> <code>int</code> <p>Number of random splits to generate</p> <code>5</code> <code>sampling_fraction</code> <code>float</code> <p>Fraction of entries to use for training</p> <code>0.8</code> <code>random_state</code> <code>int or None</code> <p>Random seed for reproducibility</p> <code>None</code> <code>missing_values</code> <code>float or None</code> <p>Value that marks missing entries</p> <code>np.nan</code> Source code in <code>pysrf/cross_validation.py</code> <pre><code>def __init__(\n    self,\n    n_repeats: int = 5,\n    sampling_fraction: float = 0.8,\n    random_state: int | None = None,\n    missing_values: float | None = np.nan,\n):\n    self.n_repeats = n_repeats\n    self.sampling_fraction = sampling_fraction\n    self.random_state = random_state\n    self.missing_values = missing_values\n</code></pre>"},{"location":"api/cross_validation/#grid-search","title":"Grid Search","text":""},{"location":"api/cross_validation/#pysrf.ADMMGridSearchCV","title":"ADMMGridSearchCV","text":"<pre><code>ADMMGridSearchCV(\n    estimator: BaseEstimator,\n    param_grid: dict[str, list],\n    cv: EntryMaskSplit,\n    n_jobs: int = -1,\n    verbose: int = 0,\n    fit_final_estimator: bool = False,\n)\n</code></pre> <p>Grid search cross-validation for matrix completion.</p> <p>Performs exhaustive grid search over specified parameter values with entry-wise cross-validation for symmetric matrices.</p> <p>Parameters:</p> Name Type Description Default <code>estimator</code> <code>BaseEstimator</code> <p>Model instance to optimize</p> required <code>param_grid</code> <code>dict</code> <p>Dictionary with parameter names as keys and lists of values to try</p> required <code>cv</code> <code>EntryMaskSplit</code> <p>Cross-validation splitter</p> required <code>n_jobs</code> <code>int</code> <p>Number of parallel jobs (-1 uses all processors)</p> <code>-1</code> <code>verbose</code> <code>int</code> <p>Verbosity level</p> <code>0</code> <code>fit_final_estimator</code> <code>bool</code> <p>Whether to fit the model on full data with best parameters</p> <code>False</code> <p>Attributes:</p> Name Type Description <code>best_params_</code> <code>dict</code> <p>Parameters that gave the best score</p> <code>best_score_</code> <code>float</code> <p>Best validation score achieved</p> <code>cv_results_</code> <code>DataFrame</code> <p>Detailed results for all parameter combinations</p> <code>best_estimator_</code> <code>estimator</code> <p>Fitted estimator with best parameters (if fit_final_estimator=True)</p> Source code in <code>pysrf/cross_validation.py</code> <pre><code>def __init__(\n    self,\n    estimator: BaseEstimator,\n    param_grid: dict[str, list],\n    cv: EntryMaskSplit,\n    n_jobs: int = -1,\n    verbose: int = 0,\n    fit_final_estimator: bool = False,\n):\n    self.estimator = estimator\n    self.param_grid = param_grid\n    self.cv = cv\n    self.n_jobs = n_jobs\n    self.verbose = verbose\n    self.fit_final_estimator = fit_final_estimator\n</code></pre>"},{"location":"api/cross_validation/#utility-functions","title":"Utility Functions","text":""},{"location":"api/cross_validation/#pysrf.cross_validation.mask_missing_entries","title":"mask_missing_entries","text":"<pre><code>mask_missing_entries(\n    x: np.ndarray,\n    sampling_fraction: float,\n    rng: np.random.RandomState,\n    missing_values: float | None = np.nan,\n) -&gt; np.ndarray\n</code></pre> <p>Create a missing mask for symmetric matrix cross-validation.</p> <p>Subsample from valid upper triangular positions to keep as observed, maintaining symmetry. The diagonal is always observed to ensure proper scaling of the optimization.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>Input symmetric matrix</p> required <code>sampling_fraction</code> <code>float</code> <p>Fraction of entries to keep as observed (0.0 to 1.0)</p> required <code>rng</code> <code>RandomState</code> <p>Random number generator</p> required <code>missing_values</code> <code>float or None</code> <p>Value that marks missing entries</p> <code>nan</code> <p>Returns:</p> Name Type Description <code>missing_mask</code> <code>ndarray of bool</code> <p>Boolean mask where True indicates missing entries</p> Source code in <code>pysrf/cross_validation.py</code> <pre><code>def mask_missing_entries(\n    x: np.ndarray,\n    sampling_fraction: float,\n    rng: np.random.RandomState,\n    missing_values: float | None = np.nan,\n) -&gt; np.ndarray:\n    \"\"\"\n    Create a missing mask for symmetric matrix cross-validation.\n\n    Subsample from valid upper triangular positions to keep as observed,\n    maintaining symmetry. The diagonal is always observed to ensure proper\n    scaling of the optimization.\n\n    Parameters\n    ----------\n    x : ndarray\n        Input symmetric matrix\n    sampling_fraction : float\n        Fraction of entries to keep as observed (0.0 to 1.0)\n    rng : RandomState\n        Random number generator\n    missing_values : float or None\n        Value that marks missing entries\n\n    Returns\n    -------\n    missing_mask : ndarray of bool\n        Boolean mask where True indicates missing entries\n    \"\"\"\n    observed_mask = ~np.isnan(x) if missing_values is np.nan else x != missing_values\n\n    triu_i, triu_j = np.triu_indices_from(x, k=1)\n    triu_observed = observed_mask[triu_i, triu_j]\n    valid_positions = np.where(triu_observed)[0]\n\n    n_to_keep = int(sampling_fraction * len(valid_positions))\n    if n_to_keep == 0:\n        return np.ones_like(x, dtype=bool)\n\n    # Subsample from valid upper triangular positions to keep as observed\n    keep_positions = rng.choice(valid_positions, size=n_to_keep, replace=False)\n\n    # Create missing mask directly - start with all missing\n    missing_mask = np.ones_like(x, dtype=bool)\n\n    # Set kept positions as observed (False = not missing)\n    keep_i = triu_i[keep_positions]\n    keep_j = triu_j[keep_positions]\n    missing_mask[keep_i, keep_j] = False\n    missing_mask[keep_j, keep_i] = False\n\n    # Diagonal is always observed to ensure proper scaling of the optimization\n    np.fill_diagonal(missing_mask, False)\n\n    return missing_mask\n</code></pre>"},{"location":"api/cross_validation/#pysrf.cross_validation.fit_and_score","title":"fit_and_score","text":"<pre><code>fit_and_score(\n    estimator: BaseEstimator,\n    x: np.ndarray,\n    val_mask: np.ndarray,\n    fit_params: dict,\n    split_idx: int | None = None,\n) -&gt; dict\n</code></pre> <p>Fit estimator with parameters and return validation score.</p> <p>Parameters:</p> Name Type Description Default <code>estimator</code> <code>BaseEstimator</code> <p>Model instance to fit</p> required <code>x</code> <code>ndarray</code> <p>Full data matrix</p> required <code>val_mask</code> <code>ndarray</code> <p>Boolean mask indicating validation entries</p> required <code>fit_params</code> <code>dict</code> <p>Parameters to set on the estimator</p> required <code>split_idx</code> <code>int or None</code> <p>Index of the CV split</p> <code>None</code> <p>Returns:</p> Name Type Description <code>result</code> <code>dict</code> <p>Dictionary with score, parameters, and fitted estimator</p> Source code in <code>pysrf/cross_validation.py</code> <pre><code>def fit_and_score(\n    estimator: BaseEstimator,\n    x: np.ndarray,\n    val_mask: np.ndarray,\n    fit_params: dict,\n    split_idx: int | None = None,\n) -&gt; dict:\n    \"\"\"\n    Fit estimator with parameters and return validation score.\n\n    Parameters\n    ----------\n    estimator : BaseEstimator\n        Model instance to fit\n    x : ndarray\n        Full data matrix\n    val_mask : ndarray\n        Boolean mask indicating validation entries\n    fit_params : dict\n        Parameters to set on the estimator\n    split_idx : int or None\n        Index of the CV split\n\n    Returns\n    -------\n    result : dict\n        Dictionary with score, parameters, and fitted estimator\n    \"\"\"\n    est = clone(estimator).set_params(**fit_params)\n    est.set_params(missing_values=np.nan)\n\n    # IMPORTANT If bounds not explicitly provided, compute from original data, not just\n    # training portion\n    if \"bounds\" not in fit_params or fit_params[\"bounds\"] is None:\n        original_bounds = (np.nanmin(x), np.nanmax(x))\n        est.set_params(bounds=original_bounds)\n\n    # we consider true nan entries as missing, so we need to mask them out in the\n    # reconstruction entirely, not being able to treat them as artificial missing values.\n    already_nan = np.isnan(x)\n\n    x_copy = np.copy(x)\n    x_copy[val_mask] = np.nan\n\n    reconstruction = est.fit(x_copy).reconstruct()\n    valid_mask = val_mask &amp; ~already_nan\n    mse = np.mean((x[valid_mask] - reconstruction[valid_mask]) ** 2)\n\n    result = {\n        \"score\": mse,\n        \"split\": split_idx if split_idx is not None else 0,\n        \"estimator\": est,\n        \"params\": fit_params,\n        \"history\": est.history_,\n    }\n    return result\n</code></pre>"},{"location":"api/model/","title":"Model API","text":""},{"location":"api/model/#srf-class","title":"SRF Class","text":""},{"location":"api/model/#pysrf.SRF","title":"SRF","text":"<pre><code>SRF(\n    rank: int = 10,\n    rho: float = 3.0,\n    max_outer: int = 10,\n    max_inner: int = 30,\n    tol: float = 0.0001,\n    verbose: bool = False,\n    init: str = \"random_sqrt\",\n    random_state: int | None = None,\n    missing_values: float | None = np.nan,\n    bounds: tuple[float, float] | None = (None, None),\n)\n</code></pre> <p>             Bases: <code>TransformerMixin</code>, <code>BaseEstimator</code></p> <p>Symmetric Non-negative Matrix Factorization using ADMM.</p> <p>This class implements symmetric non-negative matrix factorization (SymNMF) using the Alternating Direction Method of Multipliers (ADMM). It can handle missing entries and optional bound constraints on the factorization.</p> <p>The algorithm solves: min_{w&gt;=0,v} ||M o (S - v)||^2_F + rho/2 ||v - ww^T||^2_F subject to optional bounds on v, where M is an observation mask.</p> <p>Parameters:</p> Name Type Description Default <code>rank</code> <code>int</code> <p>Number of factors (dimensionality of the latent space)</p> <code>10</code> <code>rho</code> <code>float</code> <p>ADMM penalty parameter controlling constraint enforcement</p> <code>3.0</code> <code>max_outer</code> <code>int</code> <p>Maximum number of ADMM outer iterations</p> <code>10</code> <code>max_inner</code> <code>int</code> <p>Maximum iterations for w-subproblem per outer iteration</p> <code>30</code> <code>tol</code> <code>float</code> <p>Convergence tolerance for constraint violation</p> <code>1e-4</code> <code>verbose</code> <code>bool</code> <p>Whether to print optimization progress</p> <code>False</code> <code>init</code> <code>str</code> <p>Method for factor initialization ('random', 'random_sqrt', 'nndsvd', 'nndsvdar', 'eigenspectrum')</p> <code>'random_sqrt'</code> <code>random_state</code> <code>int or None</code> <p>Random seed for reproducible initialization</p> <code>None</code> <code>missing_values</code> <code>float or None</code> <p>Values to be treated as missing to mask the matrix</p> <code>np.nan</code> <code>bounds</code> <code>tuple of (float, float) or None</code> <p>Tuple of (lower, upper) bounds for the auxiliary variable v. If None, the bounds are inferred from the data. In practice, one can also pass the expected bounds of the matrix (e.g. (0, 1) for cosine similarity)</p> <code>(None, None)</code> <p>Attributes:</p> Name Type Description <code>w_</code> <code>ndarray of shape (n_samples, rank)</code> <p>Learned factor matrix w</p> <code>components_</code> <code>ndarray of shape (n_samples, rank)</code> <p>Alias for w_ (sklearn compatibility)</p> <code>n_iter_</code> <code>int</code> <p>Number of ADMM iterations performed</p> <code>history_</code> <code>dict</code> <p>Dictionary containing optimization metrics per iteration</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Basic usage with complete data\n&gt;&gt;&gt; from pysrf import SRF\n&gt;&gt;&gt; model = SRF(rank=10, random_state=42)\n&gt;&gt;&gt; w = model.fit_transform(similarity_matrix)\n&gt;&gt;&gt; reconstruction = w @ w.T\n</code></pre> <pre><code>&gt;&gt;&gt; # Usage with missing data (NaN values)\n&gt;&gt;&gt; similarity_matrix[mask] = np.nan\n&gt;&gt;&gt; model = SRF(rank=10, missing_values=np.nan)\n&gt;&gt;&gt; w = model.fit_transform(similarity_matrix)\n</code></pre> References <p>.. [1] Shi et al. (2016). \"Inexact Block Coordinate Descent Methods For        Symmetric Nonnegative Matrix Factorization\"</p> Source code in <code>pysrf/model.py</code> <pre><code>def __init__(\n    self,\n    rank: int = 10,\n    rho: float = 3.0,\n    max_outer: int = 10,\n    max_inner: int = 30,\n    tol: float = 1e-4,\n    verbose: bool = False,\n    init: str = \"random_sqrt\",\n    random_state: int | None = None,\n    missing_values: float | None = np.nan,\n    bounds: tuple[float, float] | None = (None, None),\n) -&gt; None:\n    self.rank = rank\n    self.rho = rho\n    self.max_outer = max_outer\n    self.max_inner = max_inner\n    self.tol = tol\n    self.verbose = verbose\n    self.init = init\n    self.random_state = random_state\n    self.missing_values = missing_values\n    self.bounds = bounds\n</code></pre>"},{"location":"api/model/#pysrf.SRF.fit","title":"fit","text":"<pre><code>fit(x: ndarray, y: ndarray | None = None) -&gt; SRF\n</code></pre> <p>Fit the symmetric NMF model to the data.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array-like of shape (n_samples, n_samples)</code> <p>Symmetric similarity matrix. Missing values are allowed and should be marked according to the missing_values parameter.</p> required <code>y</code> <code>Ignored</code> <p>Not used, present here for API consistency by convention.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>self</code> <code>object</code> <p>Fitted estimator.</p> Source code in <code>pysrf/model.py</code> <pre><code>def fit(self, x: ndarray, y: ndarray | None = None) -&gt; SRF:\n    \"\"\"\n    Fit the symmetric NMF model to the data.\n\n    Parameters\n    ----------\n    x : array-like of shape (n_samples, n_samples)\n        Symmetric similarity matrix. Missing values are allowed and should\n        be marked according to the missing_values parameter.\n    y : Ignored\n        Not used, present here for API consistency by convention.\n\n    Returns\n    -------\n    self : object\n        Fitted estimator.\n    \"\"\"\n    self._validate_input_arguments()\n    x = x.copy()\n\n    x = validate_data(\n        self,\n        x,\n        reset=True,\n        ensure_all_finite=\"allow-nan\" if self.missing_values is np.nan else True,\n        ensure_2d=True,\n        dtype=np.float64,\n    )\n\n    self._missing_mask = get_missing_mask(x, self.missing_values)\n    if np.all(self._missing_mask):\n        raise ValueError(\n            \"No observed entries found in the data. All values are missing.\"\n        )\n\n    check_symmetric(self._missing_mask, raise_exception=True)\n    self._observation_mask = ~self._missing_mask\n    x[self._missing_mask] = 0.0\n    x = check_symmetric(x, raise_exception=True)\n\n    if np.all(self._observation_mask):\n        return self._fit_complete_data(x)\n    else:\n        return self._fit_missing_data(x)\n</code></pre>"},{"location":"api/model/#pysrf.SRF.fit_transform","title":"fit_transform","text":"<pre><code>fit_transform(\n    x: ndarray, y: ndarray | None = None\n) -&gt; ndarray\n</code></pre> <p>Fit the model and return the learned factors.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array-like of shape (n_samples, n_samples)</code> <p>Symmetric similarity matrix</p> required <code>y</code> <code>Ignored</code> <p>Not used, present here for API consistency by convention.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>w</code> <code>array-like of shape (n_samples, rank)</code> <p>Learned factor matrix</p> Source code in <code>pysrf/model.py</code> <pre><code>def fit_transform(self, x: ndarray, y: ndarray | None = None) -&gt; ndarray:\n    \"\"\"\n    Fit the model and return the learned factors.\n\n    Parameters\n    ----------\n    x : array-like of shape (n_samples, n_samples)\n        Symmetric similarity matrix\n    y : Ignored\n        Not used, present here for API consistency by convention.\n\n    Returns\n    -------\n    w : array-like of shape (n_samples, rank)\n        Learned factor matrix\n    \"\"\"\n    return self.fit(x, y).transform(x)\n</code></pre>"},{"location":"api/model/#pysrf.SRF.reconstruct","title":"reconstruct","text":"<pre><code>reconstruct(w: ndarray | None = None) -&gt; ndarray\n</code></pre> <p>Reconstruct the similarity matrix from factors.</p> <p>Parameters:</p> Name Type Description Default <code>w</code> <code>array-like of shape (n_samples, rank) or None</code> <p>Factor matrix to use for reconstruction. If None, uses the fitted factors.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>s_hat</code> <code>array-like of shape (n_samples, n_samples)</code> <p>Reconstructed similarity matrix</p> Source code in <code>pysrf/model.py</code> <pre><code>def reconstruct(self, w: ndarray | None = None) -&gt; ndarray:\n    \"\"\"\n    Reconstruct the similarity matrix from factors.\n\n    Parameters\n    ----------\n    w : array-like of shape (n_samples, rank) or None\n        Factor matrix to use for reconstruction.\n        If None, uses the fitted factors.\n\n    Returns\n    -------\n    s_hat : array-like of shape (n_samples, n_samples)\n        Reconstructed similarity matrix\n    \"\"\"\n    if w is None:\n        check_is_fitted(self)\n        w = self.w_\n\n    return w @ w.T\n</code></pre>"},{"location":"api/model/#pysrf.SRF.score","title":"score","text":"<pre><code>score(x: ndarray, y: ndarray | None = None) -&gt; float\n</code></pre> <p>Score the model using reconstruction error on observed entries only.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array-like of shape (n_samples, n_samples)</code> <p>Symmetric similarity matrix. Missing values are allowed and should be marked according to the missing_values parameter.</p> required <code>y</code> <code>Ignored</code> <p>Not used, present here for API consistency by convention.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>mse</code> <code>float</code> <p>Mean squared error of the reconstruction on observed entries.</p> Source code in <code>pysrf/model.py</code> <pre><code>def score(self, x: ndarray, y: ndarray | None = None) -&gt; float:\n    \"\"\"\n    Score the model using reconstruction error on observed entries only.\n\n    Parameters\n    ----------\n    x : array-like of shape (n_samples, n_samples)\n        Symmetric similarity matrix. Missing values are allowed and should\n        be marked according to the missing_values parameter.\n    y : Ignored\n        Not used, present here for API consistency by convention.\n\n    Returns\n    -------\n    mse : float\n        Mean squared error of the reconstruction on observed entries.\n    \"\"\"\n    check_is_fitted(self)\n    reconstruction = self.reconstruct()\n    mse = np.mean(\n        (x[self._observation_mask] - reconstruction[self._observation_mask]) ** 2\n    )\n    return mse\n</code></pre>"},{"location":"api/model/#pysrf.SRF.transform","title":"transform","text":"<pre><code>transform(x: ndarray) -&gt; ndarray\n</code></pre> <p>Project data onto the learned factor space.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>array-like of shape (n_samples, n_samples)</code> <p>Symmetric matrix to transform</p> required <p>Returns:</p> Name Type Description <code>w</code> <code>array-like of shape (n_samples, rank)</code> <p>Transformed data</p> Source code in <code>pysrf/model.py</code> <pre><code>def transform(self, x: ndarray) -&gt; ndarray:\n    \"\"\"\n    Project data onto the learned factor space.\n\n    Parameters\n    ----------\n    x : array-like of shape (n_samples, n_samples)\n        Symmetric matrix to transform\n\n    Returns\n    -------\n    w : array-like of shape (n_samples, rank)\n        Transformed data\n    \"\"\"\n    check_is_fitted(self)\n    return self.w_\n</code></pre>"},{"location":"api/utils/","title":"Utilities API","text":""},{"location":"api/utils/#initialization-functions","title":"Initialization Functions","text":""},{"location":"api/utils/#pysrf.utils.init_factor","title":"init_factor","text":"<pre><code>init_factor(\n    s: array,\n    rank: int,\n    init: str,\n    random_state: int | None = None,\n    eps: float = np.finfo(float).eps,\n) -&gt; array\n</code></pre> <p>Initialize factor matrix using specified method.</p> Source code in <code>pysrf/utils.py</code> <pre><code>def init_factor(\n    s: array,\n    rank: int,\n    init: str,\n    random_state: int | None = None,\n    eps: float = np.finfo(float).eps,\n) -&gt; array:\n    \"\"\"Initialize factor matrix using specified method.\"\"\"\n    rng = check_random_state(random_state)\n    if init == \"random\":\n        factor = 0.1 * rng.rand(s.shape[0], rank)\n    elif init == \"random_sqrt\":\n        avg = np.sqrt(s.mean() / rank)\n        factor = rng.rand(s.shape[0], rank) * avg\n    elif init == \"nndsvd\":\n        factor, _ = nndsvd(s, rank, eps, random_state)\n    elif init == \"nndsvdar\":\n        factor, _ = nndsvd(s, rank, eps, random_state)\n        avg = s.mean()\n        factor[factor == 0] = abs(\n            avg * rng.standard_normal(size=len(factor[factor == 0])) / 100\n        )\n    elif init == \"eigenspectrum\":\n        factor = eigenspectrum_initialization(s, rank, random_state)\n    else:\n        raise ValueError(f\"Invalid initialization method: {init}\")\n    return factor\n</code></pre>"},{"location":"api/utils/#pysrf.utils.eigenspectrum_initialization","title":"eigenspectrum_initialization","text":"<pre><code>eigenspectrum_initialization(\n    x: array, rank: int, random_state: int | None = None\n) -&gt; array\n</code></pre> <p>Initialize factors using eigenspectrum decomposition.</p> Source code in <code>pysrf/utils.py</code> <pre><code>def eigenspectrum_initialization(\n    x: array, rank: int, random_state: int | None = None\n) -&gt; array:\n    \"\"\"Initialize factors using eigenspectrum decomposition.\"\"\"\n    eigvals, eigvecs = np.linalg.eigh(x)\n    idx = np.argsort(np.abs(eigvals))[::-1][:rank]\n    eigenvalues_sorted = eigvals[idx]\n    eigenvectors_sorted = eigvecs[:, idx]\n    factor = eigenvectors_sorted @ np.diag(np.sqrt(np.abs(eigenvalues_sorted)))\n    factor[factor &lt; 0] = 0\n    return factor\n</code></pre>"},{"location":"api/utils/#pysrf.utils.nndsvd","title":"nndsvd","text":"<pre><code>nndsvd(\n    x: array,\n    rank: int,\n    eps: float = np.finfo(float).eps,\n    random_state: int | None = None,\n) -&gt; tuple[array, array]\n</code></pre> <p>Non-Negative Double Singular Value Decomposition initialization.</p> Source code in <code>pysrf/utils.py</code> <pre><code>def nndsvd(\n    x: array,\n    rank: int,\n    eps: float = np.finfo(float).eps,\n    random_state: int | None = None,\n) -&gt; tuple[array, array]:\n    \"\"\"Non-Negative Double Singular Value Decomposition initialization.\"\"\"\n    from sklearn.utils.extmath import randomized_svd, squared_norm\n\n    def norm(x: array) -&gt; float:\n        return np.sqrt(squared_norm(x))\n\n    u, s, v = randomized_svd(x, rank, random_state=random_state)\n    w = np.zeros_like(u)\n    h = np.zeros_like(v)\n\n    w[:, 0] = np.sqrt(s[0]) * np.abs(u[:, 0])\n    h[0, :] = np.sqrt(s[0]) * np.abs(v[0, :])\n\n    for j in range(1, rank):\n        x_col, y_col = u[:, j], v[j, :]\n        x_p, y_p = np.maximum(x_col, 0), np.maximum(y_col, 0)\n        x_n, y_n = np.abs(np.minimum(x_col, 0)), np.abs(np.minimum(y_col, 0))\n        x_p_nrm, y_p_nrm = norm(x_p), norm(y_p)\n        x_n_nrm, y_n_nrm = norm(x_n), norm(y_n)\n        m_p, m_n = x_p_nrm * y_p_nrm, x_n_nrm * y_n_nrm\n\n        if m_p &gt; m_n:\n            u_update = x_p / x_p_nrm\n            v_update = y_p / y_p_nrm\n            sigma = m_p\n        else:\n            u_update = x_n / x_n_nrm\n            v_update = y_n / y_n_nrm\n            sigma = m_n\n\n        lbd = np.sqrt(s[j] * sigma)\n        w[:, j] = lbd * u_update\n        h[j, :] = lbd * v_update\n\n    w[w &lt; eps] = 0\n    h[h &lt; eps] = 0\n    np.abs(w, out=w)\n    np.abs(h, out=h)\n    return w, h\n</code></pre>"},{"location":"api/utils/#missing-data-utilities","title":"Missing Data Utilities","text":""},{"location":"api/utils/#pysrf.utils.get_missing_mask","title":"get_missing_mask","text":"<pre><code>get_missing_mask(\n    x: array, missing_values: float | None\n) -&gt; array\n</code></pre> Source code in <code>pysrf/utils.py</code> <pre><code>def get_missing_mask(x: array, missing_values: float | None) -&gt; array:\n    if missing_values is np.nan:\n        return np.isnan(x)\n    elif missing_values is None:\n        return np.isnan(x)\n    else:\n        return x == missing_values\n</code></pre>"},{"location":"api/utils/#pysrf.utils.validate_missing_values","title":"validate_missing_values","text":"<pre><code>validate_missing_values(\n    missing_values: float | None,\n) -&gt; None\n</code></pre> <p>Validate the missing_values parameter.</p> Source code in <code>pysrf/utils.py</code> <pre><code>def validate_missing_values(missing_values: float | None) -&gt; None:\n    \"\"\"Validate the missing_values parameter.\"\"\"\n    if missing_values is not np.nan and missing_values is not None:\n        if not isinstance(missing_values, (int, float)):\n            raise ValueError(\n                f\"missing_values must be np.nan, None, or a numeric value, got {type(missing_values)}\"\n            )\n</code></pre>"},{"location":"api/utils/#evaluation-metrics","title":"Evaluation Metrics","text":""},{"location":"api/utils/#pysrf.utils.explained_variance","title":"explained_variance","text":"<pre><code>explained_variance(\n    x: array, x_hat: array, center: bool = False\n) -&gt; float\n</code></pre> Source code in <code>pysrf/utils.py</code> <pre><code>def explained_variance(x: array, x_hat: array, center: bool = False) -&gt; float:\n    x_upper = x[np.triu_indices(x.shape[0], k=1)]\n    x_hat_upper = x_hat[np.triu_indices(x_hat.shape[0], k=1)]\n\n    rss = np.sum((x_upper - x_hat_upper) ** 2)\n\n    if center:\n        tss = np.sum((x_upper - np.mean(x_upper)) ** 2)\n    else:\n        tss = np.sum(x_upper**2)\n\n    if tss == 0:\n        return 1.0 if rss == 0 else 0.0\n\n    return 1 - (rss / tss)\n</code></pre>"},{"location":"api/utils/#pysrf.utils.sse","title":"sse","text":"<pre><code>sse(x: array, x_hat: array) -&gt; float\n</code></pre> Source code in <code>pysrf/utils.py</code> <pre><code>def sse(x: array, x_hat: array) -&gt; float:\n    x_upper = x[np.triu_indices(x.shape[0], k=1)]\n    x_hat_upper = x_hat[np.triu_indices(x_hat.shape[0], k=1)]\n    return np.sum((x_upper - x_hat_upper) ** 2)\n</code></pre>"},{"location":"api/utils/#pysrf.utils.frobenius_norm","title":"frobenius_norm","text":"<pre><code>frobenius_norm(x: array, x_hat: array) -&gt; float\n</code></pre> Source code in <code>pysrf/utils.py</code> <pre><code>def frobenius_norm(x: array, x_hat: array) -&gt; float:\n    return np.linalg.norm(x - x_hat, ord=\"fro\")\n</code></pre>"}]}